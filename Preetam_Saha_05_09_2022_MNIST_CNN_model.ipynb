{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNokkk9wHbX/ULuTv3CbL8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/CNN_from_Scratch/blob/main/Preetam_Saha_05_09_2022_MNIST_CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE-DC5HheVQh",
        "outputId": "424ec078-c3d8-4c53-dc87-30c0ca6a321d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-05 15:07:12--  https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/training.pt [following]\n",
            "--2022-09-05 15:07:13--  https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47520431 (45M) [application/octet-stream]\n",
            "Saving to: ‘training.pt’\n",
            "\n",
            "training.pt         100%[===================>]  45.32M   276MB/s    in 0.2s    \n",
            "\n",
            "2022-09-05 15:07:14 (276 MB/s) - ‘training.pt’ saved [47520431/47520431]\n",
            "\n",
            "--2022-09-05 15:07:15--  https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/test.pt\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/test.pt [following]\n",
            "--2022-09-05 15:07:15--  https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/test.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7920431 (7.6M) [application/octet-stream]\n",
            "Saving to: ‘test.pt’\n",
            "\n",
            "test.pt             100%[===================>]   7.55M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-09-05 15:07:16 (129 MB/s) - ‘test.pt’ saved [7920431/7920431]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/training.pt #.pt = in form of tensors\n",
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/test.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchsummary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Adam, RMSprop\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8TsE8fVhepce"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = (torch.load('training.pt'),torch.load('test.pt'))"
      ],
      "metadata": {
        "id": "2KDDgEtAfzUI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#in pytorch channel of the image second dimension , 1st=batchsize, 2nd = channel, 3rd = width, 4th = height \n",
        "#tensorflow channel is the fourth dimension\n",
        "\n",
        "x_train = x_train.reshape(-1,1,28,28) #1 channel for grey scale\n",
        "x_test = x_test.reshape(-1,1,28,28) #second 1 for channel , cant build cnn without this information, -1 for batchsize"
      ],
      "metadata": {
        "id": "H9fUyd_tgYW7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "VlJnE8MUiEea"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "Image.fromarray(x_train[idx,0,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "g6j9MSxCiO6T",
        "outputId": "efb5f905-e692-4086-e3ed-69c0d4a9f8ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FADC90E9290>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65gA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fgCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=300\n",
        "Image.fromarray(x_train[idx,0,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "gIuPpxCpinTo",
        "outputId": "c3b4e5ed-9449-4086-cbe2-ba2bd81f8179"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FAD56D37AD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzklEQVR4nGNgGOyg691NF1xy0/79+/cCh5z9g38T/30QwybFv+Dvv3+7/23Bqm/Hvx3n//37YYxNrvrPOUH9f/8asGp8+k+bYem/+WzYJd+Ka72+JYHdqVf/ZV75boRdjsHmJ5qFTEjsI5MYGJQ5cOhkWPLv879IHHIWPzcavj6FXY796k8jhivfNbHaaae59BwDAzs3Vp1X/skxMFz5Z4JNjuX1VQ4G1c8fFbBJCn84wcJ68F8ddge9+Hfl1r/D/NglXW78+7eMD7scVQEAfcJRtn7OEhMAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MNIST_CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=16, kernel_size=3, padding=1 ) #in_channel = channel, out_channels=no of filters, kernel_Size = filter size\n",
        "    self.conv2 = nn.Conv2d(in_channels=16,out_channels=32, kernel_size=3, padding=1 )\n",
        "    self.conv3 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=3, padding=1 )\n",
        "    self.conv4 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=3, padding=1 )\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=16)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=64)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride = 2) #by pooling only reduction happenes, stride = 2 means jump of 2 pixels\n",
        "    self.h1 = nn.Linear(in_features=1*1*128, out_features= 512)\n",
        "    self.h2 = nn.Linear(in_features=512, out_features= 256)\n",
        "    self.h3 = nn.Linear(in_features= 256, out_features= 32)\n",
        "    self.out = nn.Linear(in_features = 32, out_features=10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.pool(x)\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.view(x.size()[0],-1)\n",
        "    #print(x.size())\n",
        "\n",
        "    x = F.relu(self.h1(x))\n",
        "    x = F.relu(self.h2(x))\n",
        "    x = F.relu(self.h3(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "m5Ztmwbxir_U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = MNIST_CNN()\n",
        "list(cnn_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG3ksv36m-n9",
        "outputId": "30ea62d5-4e82-40ef-bd23-fccde4066171"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[[[-0.2961, -0.2786, -0.2676],\n",
              "           [-0.1988,  0.1258,  0.2130],\n",
              "           [ 0.3286,  0.0270, -0.0315]]],\n",
              " \n",
              " \n",
              "         [[[-0.1522,  0.0857,  0.2052],\n",
              "           [-0.0135,  0.1384,  0.2465],\n",
              "           [-0.2061,  0.2273, -0.3003]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1291, -0.1142, -0.0600],\n",
              "           [-0.0831, -0.1270,  0.2767],\n",
              "           [-0.0110,  0.1529,  0.0528]]],\n",
              " \n",
              " \n",
              "         [[[-0.2403,  0.3324, -0.1415],\n",
              "           [-0.1795,  0.2097,  0.3105],\n",
              "           [ 0.2698,  0.1806,  0.1436]]],\n",
              " \n",
              " \n",
              "         [[[ 0.3041,  0.2870, -0.0990],\n",
              "           [-0.0819, -0.3175, -0.1505],\n",
              "           [-0.2464,  0.2564,  0.1072]]],\n",
              " \n",
              " \n",
              "         [[[-0.2280,  0.1939,  0.1695],\n",
              "           [-0.1088,  0.3291, -0.2146],\n",
              "           [-0.1906,  0.2814, -0.3258]]],\n",
              " \n",
              " \n",
              "         [[[-0.2537,  0.0983,  0.0383],\n",
              "           [-0.0856,  0.0697,  0.0867],\n",
              "           [ 0.0890,  0.1012, -0.1497]]],\n",
              " \n",
              " \n",
              "         [[[-0.1095, -0.2853, -0.0629],\n",
              "           [-0.3049, -0.1571,  0.1195],\n",
              "           [-0.3313,  0.2775,  0.1043]]],\n",
              " \n",
              " \n",
              "         [[[-0.1209, -0.0918,  0.1406],\n",
              "           [-0.1383,  0.2011, -0.2020],\n",
              "           [-0.1185,  0.1714,  0.1811]]],\n",
              " \n",
              " \n",
              "         [[[ 0.3101,  0.1662, -0.2666],\n",
              "           [ 0.2743,  0.3330,  0.2814],\n",
              "           [ 0.1275,  0.2693, -0.2728]]],\n",
              " \n",
              " \n",
              "         [[[ 0.2477, -0.2291, -0.1351],\n",
              "           [ 0.1601, -0.2287,  0.3022],\n",
              "           [ 0.2449, -0.0935, -0.1802]]],\n",
              " \n",
              " \n",
              "         [[[-0.2194,  0.0801, -0.2652],\n",
              "           [ 0.1928,  0.3098,  0.0466],\n",
              "           [-0.1477,  0.3289, -0.2815]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1054,  0.1551, -0.3094],\n",
              "           [-0.0734,  0.2639, -0.1357],\n",
              "           [ 0.1651, -0.2012, -0.2122]]],\n",
              " \n",
              " \n",
              "         [[[ 0.3189,  0.0416,  0.2692],\n",
              "           [ 0.2709,  0.2709, -0.0623],\n",
              "           [ 0.1132, -0.1021,  0.1114]]],\n",
              " \n",
              " \n",
              "         [[[-0.0466,  0.2250, -0.2447],\n",
              "           [ 0.0488,  0.2455, -0.1910],\n",
              "           [-0.2607,  0.2446, -0.2725]]],\n",
              " \n",
              " \n",
              "         [[[-0.3233,  0.3032,  0.0438],\n",
              "           [-0.2070,  0.1118,  0.1773],\n",
              "           [ 0.0261, -0.2212,  0.2654]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.2259,  0.2752,  0.2578, -0.0266, -0.0783, -0.0408,  0.2498,  0.3333,\n",
              "          0.1592,  0.1326, -0.2315, -0.0244, -0.2761,  0.0531, -0.2950,  0.1404],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.0650, -0.0236,  0.0641],\n",
              "           [ 0.0536,  0.0683,  0.0210],\n",
              "           [-0.0622,  0.0307,  0.0241]],\n",
              " \n",
              "          [[ 0.0682, -0.0783,  0.0104],\n",
              "           [ 0.0622, -0.0752,  0.0166],\n",
              "           [-0.0477,  0.0682, -0.0442]],\n",
              " \n",
              "          [[ 0.0085,  0.0101, -0.0710],\n",
              "           [ 0.0746, -0.0559, -0.0095],\n",
              "           [-0.0779,  0.0284,  0.0642]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0475,  0.0527,  0.0796],\n",
              "           [ 0.0080, -0.0586,  0.0449],\n",
              "           [ 0.0161,  0.0362, -0.0824]],\n",
              " \n",
              "          [[ 0.0707, -0.0647, -0.0586],\n",
              "           [ 0.0601,  0.0478, -0.0825],\n",
              "           [ 0.0187,  0.0402,  0.0815]],\n",
              " \n",
              "          [[-0.0412, -0.0804, -0.0538],\n",
              "           [ 0.0329, -0.0622, -0.0132],\n",
              "           [ 0.0553,  0.0322,  0.0178]]],\n",
              " \n",
              " \n",
              "         [[[-0.0461, -0.0620, -0.0519],\n",
              "           [ 0.0589,  0.0693, -0.0480],\n",
              "           [-0.0621, -0.0466,  0.0710]],\n",
              " \n",
              "          [[ 0.0279,  0.0113, -0.0284],\n",
              "           [ 0.0136, -0.0468,  0.0509],\n",
              "           [-0.0548,  0.0734, -0.0444]],\n",
              " \n",
              "          [[-0.0798, -0.0067, -0.0199],\n",
              "           [-0.0466, -0.0284, -0.0532],\n",
              "           [ 0.0087, -0.0129,  0.0508]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0558, -0.0633, -0.0138],\n",
              "           [-0.0099, -0.0362,  0.0697],\n",
              "           [ 0.0238, -0.0742, -0.0364]],\n",
              " \n",
              "          [[-0.0303, -0.0282, -0.0004],\n",
              "           [ 0.0397,  0.0747,  0.0150],\n",
              "           [ 0.0016, -0.0820,  0.0252]],\n",
              " \n",
              "          [[ 0.0623,  0.0013,  0.0677],\n",
              "           [-0.0201,  0.0404, -0.0468],\n",
              "           [ 0.0718, -0.0267, -0.0366]]],\n",
              " \n",
              " \n",
              "         [[[-0.0744, -0.0369,  0.0246],\n",
              "           [-0.0414, -0.0138,  0.0003],\n",
              "           [-0.0181, -0.0301,  0.0016]],\n",
              " \n",
              "          [[ 0.0145,  0.0012,  0.0698],\n",
              "           [ 0.0644,  0.0202, -0.0762],\n",
              "           [ 0.0806,  0.0805, -0.0266]],\n",
              " \n",
              "          [[-0.0826,  0.0814,  0.0156],\n",
              "           [ 0.0297,  0.0376, -0.0820],\n",
              "           [ 0.0701,  0.0726,  0.0097]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0567,  0.0238, -0.0093],\n",
              "           [ 0.0497, -0.0253,  0.0210],\n",
              "           [ 0.0608,  0.0630, -0.0241]],\n",
              " \n",
              "          [[ 0.0473, -0.0634,  0.0782],\n",
              "           [ 0.0418,  0.0135, -0.0057],\n",
              "           [-0.0457, -0.0247, -0.0131]],\n",
              " \n",
              "          [[-0.0151,  0.0620,  0.0459],\n",
              "           [-0.0401,  0.0734,  0.0418],\n",
              "           [-0.0294,  0.0023, -0.0405]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.0479,  0.0799, -0.0577],\n",
              "           [ 0.0615,  0.0316, -0.0519],\n",
              "           [-0.0828, -0.0815,  0.0445]],\n",
              " \n",
              "          [[ 0.0399,  0.0305, -0.0289],\n",
              "           [-0.0140, -0.0439,  0.0045],\n",
              "           [ 0.0744, -0.0163, -0.0361]],\n",
              " \n",
              "          [[-0.0547,  0.0033, -0.0656],\n",
              "           [-0.0282, -0.0135, -0.0826],\n",
              "           [-0.0544, -0.0724, -0.0499]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0524,  0.0118,  0.0549],\n",
              "           [-0.0412, -0.0073,  0.0789],\n",
              "           [-0.0724,  0.0274, -0.0149]],\n",
              " \n",
              "          [[-0.0043,  0.0365,  0.0043],\n",
              "           [-0.0081, -0.0772, -0.0459],\n",
              "           [-0.0685,  0.0257,  0.0558]],\n",
              " \n",
              "          [[ 0.0557,  0.0237, -0.0195],\n",
              "           [-0.0065, -0.0669, -0.0598],\n",
              "           [-0.0712,  0.0108,  0.0438]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0413, -0.0214,  0.0460],\n",
              "           [-0.0722,  0.0165, -0.0579],\n",
              "           [-0.0299, -0.0329,  0.0370]],\n",
              " \n",
              "          [[ 0.0753, -0.0266,  0.0704],\n",
              "           [ 0.0255, -0.0340,  0.0428],\n",
              "           [ 0.0546, -0.0450,  0.0478]],\n",
              " \n",
              "          [[ 0.0233, -0.0444,  0.0059],\n",
              "           [-0.0659,  0.0824, -0.0643],\n",
              "           [-0.0606,  0.0033, -0.0012]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0667, -0.0023, -0.0686],\n",
              "           [ 0.0412,  0.0472, -0.0218],\n",
              "           [-0.0124,  0.0787, -0.0605]],\n",
              " \n",
              "          [[ 0.0821,  0.0788, -0.0784],\n",
              "           [-0.0020, -0.0169,  0.0475],\n",
              "           [ 0.0698,  0.0680,  0.0761]],\n",
              " \n",
              "          [[-0.0688, -0.0091,  0.0045],\n",
              "           [-0.0462,  0.0737, -0.0728],\n",
              "           [ 0.0819, -0.0650,  0.0818]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0309, -0.0446,  0.0672],\n",
              "           [-0.0775,  0.0672, -0.0380],\n",
              "           [ 0.0119, -0.0439,  0.0418]],\n",
              " \n",
              "          [[ 0.0252, -0.0507, -0.0373],\n",
              "           [-0.0652,  0.0510,  0.0338],\n",
              "           [-0.0531,  0.0286,  0.0509]],\n",
              " \n",
              "          [[ 0.0692,  0.0460,  0.0022],\n",
              "           [ 0.0385, -0.0044, -0.0666],\n",
              "           [ 0.0577,  0.0075,  0.0638]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0299, -0.0461,  0.0149],\n",
              "           [-0.0379,  0.0202,  0.0209],\n",
              "           [-0.0023,  0.0693, -0.0675]],\n",
              " \n",
              "          [[ 0.0154,  0.0743,  0.0072],\n",
              "           [-0.0678, -0.0106, -0.0435],\n",
              "           [-0.0457, -0.0763,  0.0507]],\n",
              " \n",
              "          [[-0.0221,  0.0433,  0.0365],\n",
              "           [-0.0067,  0.0746, -0.0744],\n",
              "           [ 0.0073, -0.0401,  0.0095]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0439, -0.0240, -0.0776, -0.0098,  0.0728,  0.0687,  0.0666,  0.0479,\n",
              "          0.0091, -0.0258,  0.0188,  0.0199, -0.0620,  0.0816, -0.0518, -0.0250,\n",
              "          0.0683, -0.0476,  0.0568, -0.0415,  0.0751, -0.0490, -0.0537, -0.0685,\n",
              "         -0.0636,  0.0268, -0.0298, -0.0640, -0.0231, -0.0330, -0.0206,  0.0685],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.0152,  0.0537, -0.0229],\n",
              "           [-0.0396,  0.0452, -0.0122],\n",
              "           [-0.0503,  0.0498, -0.0026]],\n",
              " \n",
              "          [[ 0.0268,  0.0305,  0.0167],\n",
              "           [-0.0463,  0.0129, -0.0519],\n",
              "           [ 0.0565,  0.0196,  0.0567]],\n",
              " \n",
              "          [[ 0.0308, -0.0401, -0.0551],\n",
              "           [-0.0557, -0.0488,  0.0216],\n",
              "           [-0.0573, -0.0458, -0.0363]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0582,  0.0316, -0.0299],\n",
              "           [-0.0280,  0.0062, -0.0459],\n",
              "           [ 0.0265,  0.0215,  0.0349]],\n",
              " \n",
              "          [[ 0.0031, -0.0361,  0.0479],\n",
              "           [ 0.0361, -0.0188, -0.0247],\n",
              "           [-0.0577, -0.0580, -0.0385]],\n",
              " \n",
              "          [[-0.0106, -0.0317, -0.0294],\n",
              "           [ 0.0394, -0.0550, -0.0404],\n",
              "           [ 0.0427,  0.0054, -0.0114]]],\n",
              " \n",
              " \n",
              "         [[[-0.0555, -0.0410,  0.0023],\n",
              "           [ 0.0577,  0.0236, -0.0247],\n",
              "           [-0.0342, -0.0488,  0.0491]],\n",
              " \n",
              "          [[-0.0509,  0.0313, -0.0572],\n",
              "           [-0.0080,  0.0435, -0.0518],\n",
              "           [-0.0266,  0.0175,  0.0447]],\n",
              " \n",
              "          [[ 0.0116,  0.0096,  0.0389],\n",
              "           [ 0.0585,  0.0310, -0.0260],\n",
              "           [ 0.0124,  0.0270,  0.0281]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0552,  0.0129, -0.0460],\n",
              "           [-0.0013, -0.0496,  0.0096],\n",
              "           [-0.0141, -0.0194,  0.0200]],\n",
              " \n",
              "          [[-0.0318,  0.0401,  0.0521],\n",
              "           [-0.0559, -0.0189, -0.0245],\n",
              "           [ 0.0116, -0.0353, -0.0538]],\n",
              " \n",
              "          [[ 0.0534, -0.0406, -0.0350],\n",
              "           [-0.0174, -0.0488, -0.0337],\n",
              "           [ 0.0528, -0.0336, -0.0354]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0015,  0.0524,  0.0228],\n",
              "           [-0.0377, -0.0278,  0.0283],\n",
              "           [-0.0399,  0.0163, -0.0004]],\n",
              " \n",
              "          [[-0.0249,  0.0209,  0.0151],\n",
              "           [ 0.0468,  0.0361,  0.0252],\n",
              "           [ 0.0035,  0.0237, -0.0260]],\n",
              " \n",
              "          [[ 0.0196, -0.0382,  0.0571],\n",
              "           [ 0.0453, -0.0117, -0.0248],\n",
              "           [ 0.0050,  0.0221,  0.0518]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0518,  0.0534, -0.0180],\n",
              "           [-0.0252,  0.0401, -0.0548],\n",
              "           [-0.0320,  0.0332,  0.0008]],\n",
              " \n",
              "          [[-0.0506, -0.0271, -0.0258],\n",
              "           [ 0.0047, -0.0183,  0.0297],\n",
              "           [ 0.0329,  0.0195,  0.0125]],\n",
              " \n",
              "          [[-0.0008, -0.0528,  0.0392],\n",
              "           [-0.0496,  0.0469, -0.0061],\n",
              "           [-0.0221,  0.0049,  0.0078]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.0029, -0.0559, -0.0214],\n",
              "           [-0.0387, -0.0302, -0.0518],\n",
              "           [ 0.0453,  0.0396,  0.0110]],\n",
              " \n",
              "          [[ 0.0551,  0.0424,  0.0012],\n",
              "           [ 0.0126,  0.0522,  0.0124],\n",
              "           [-0.0190,  0.0092,  0.0566]],\n",
              " \n",
              "          [[-0.0298,  0.0008, -0.0174],\n",
              "           [ 0.0420, -0.0278,  0.0353],\n",
              "           [ 0.0250,  0.0536, -0.0359]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0063,  0.0271,  0.0462],\n",
              "           [ 0.0002,  0.0439,  0.0230],\n",
              "           [ 0.0188,  0.0127,  0.0400]],\n",
              " \n",
              "          [[ 0.0485,  0.0509,  0.0152],\n",
              "           [ 0.0499, -0.0138, -0.0408],\n",
              "           [ 0.0283, -0.0569, -0.0049]],\n",
              " \n",
              "          [[ 0.0411, -0.0267, -0.0237],\n",
              "           [ 0.0147, -0.0366,  0.0453],\n",
              "           [-0.0090, -0.0392,  0.0295]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0456,  0.0253, -0.0008],\n",
              "           [-0.0275, -0.0083,  0.0178],\n",
              "           [-0.0149,  0.0541, -0.0147]],\n",
              " \n",
              "          [[-0.0282,  0.0169,  0.0348],\n",
              "           [-0.0420,  0.0379, -0.0353],\n",
              "           [-0.0448, -0.0206,  0.0410]],\n",
              " \n",
              "          [[-0.0138,  0.0504, -0.0364],\n",
              "           [-0.0086,  0.0039,  0.0053],\n",
              "           [-0.0396, -0.0125,  0.0267]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0200,  0.0426,  0.0319],\n",
              "           [-0.0180,  0.0296,  0.0442],\n",
              "           [-0.0234,  0.0246, -0.0287]],\n",
              " \n",
              "          [[-0.0286, -0.0254,  0.0519],\n",
              "           [ 0.0082,  0.0485,  0.0262],\n",
              "           [ 0.0069,  0.0129,  0.0095]],\n",
              " \n",
              "          [[ 0.0579, -0.0452, -0.0040],\n",
              "           [-0.0382, -0.0505, -0.0174],\n",
              "           [ 0.0249,  0.0561,  0.0241]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0261,  0.0346,  0.0525],\n",
              "           [ 0.0441,  0.0040,  0.0018],\n",
              "           [ 0.0190, -0.0085,  0.0073]],\n",
              " \n",
              "          [[ 0.0078, -0.0167,  0.0130],\n",
              "           [-0.0262,  0.0204, -0.0157],\n",
              "           [-0.0203,  0.0229, -0.0306]],\n",
              " \n",
              "          [[ 0.0419, -0.0166, -0.0083],\n",
              "           [-0.0353,  0.0097, -0.0010],\n",
              "           [-0.0088,  0.0244,  0.0466]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0483, -0.0577,  0.0377],\n",
              "           [ 0.0064,  0.0525, -0.0561],\n",
              "           [-0.0265, -0.0392, -0.0288]],\n",
              " \n",
              "          [[-0.0460, -0.0351, -0.0543],\n",
              "           [ 0.0436,  0.0153, -0.0009],\n",
              "           [-0.0121, -0.0148,  0.0213]],\n",
              " \n",
              "          [[-0.0156,  0.0379,  0.0351],\n",
              "           [-0.0004,  0.0323, -0.0496],\n",
              "           [-0.0157,  0.0044, -0.0264]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0021, -0.0340, -0.0350,  0.0442,  0.0082,  0.0223,  0.0089, -0.0378,\n",
              "          0.0342, -0.0146, -0.0485,  0.0151,  0.0526, -0.0282,  0.0171,  0.0038,\n",
              "          0.0021, -0.0150,  0.0373, -0.0145,  0.0126,  0.0154, -0.0472, -0.0068,\n",
              "          0.0189, -0.0541, -0.0349,  0.0335, -0.0348, -0.0370,  0.0506, -0.0243,\n",
              "         -0.0312,  0.0488,  0.0356,  0.0511,  0.0344,  0.0142, -0.0540, -0.0564,\n",
              "         -0.0317,  0.0538, -0.0275,  0.0561, -0.0183, -0.0006, -0.0472,  0.0432,\n",
              "          0.0282, -0.0305,  0.0538,  0.0067, -0.0008, -0.0228,  0.0228,  0.0094,\n",
              "          0.0005,  0.0325, -0.0399, -0.0432,  0.0292,  0.0191,  0.0069, -0.0378],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.0301, -0.0112, -0.0042],\n",
              "           [-0.0317,  0.0007, -0.0091],\n",
              "           [-0.0098,  0.0242, -0.0076]],\n",
              " \n",
              "          [[-0.0361, -0.0228,  0.0087],\n",
              "           [-0.0040,  0.0075, -0.0381],\n",
              "           [ 0.0273, -0.0372, -0.0404]],\n",
              " \n",
              "          [[-0.0415,  0.0292, -0.0188],\n",
              "           [ 0.0268,  0.0103,  0.0151],\n",
              "           [ 0.0282, -0.0037,  0.0415]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0382, -0.0010, -0.0253],\n",
              "           [-0.0065,  0.0059,  0.0021],\n",
              "           [-0.0415, -0.0109,  0.0036]],\n",
              " \n",
              "          [[ 0.0200,  0.0336,  0.0005],\n",
              "           [ 0.0083,  0.0192, -0.0186],\n",
              "           [-0.0293, -0.0342, -0.0133]],\n",
              " \n",
              "          [[ 0.0329,  0.0104,  0.0251],\n",
              "           [-0.0196,  0.0158, -0.0346],\n",
              "           [-0.0257, -0.0244,  0.0090]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0365,  0.0375, -0.0256],\n",
              "           [-0.0226, -0.0307, -0.0289],\n",
              "           [ 0.0075, -0.0223, -0.0096]],\n",
              " \n",
              "          [[-0.0084,  0.0356, -0.0407],\n",
              "           [-0.0308,  0.0290, -0.0147],\n",
              "           [ 0.0207, -0.0267, -0.0386]],\n",
              " \n",
              "          [[-0.0053, -0.0098,  0.0006],\n",
              "           [-0.0131, -0.0309,  0.0008],\n",
              "           [-0.0251,  0.0179, -0.0146]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0121,  0.0060, -0.0403],\n",
              "           [-0.0036,  0.0414, -0.0335],\n",
              "           [-0.0114,  0.0010, -0.0047]],\n",
              " \n",
              "          [[-0.0284,  0.0232, -0.0250],\n",
              "           [ 0.0262,  0.0302, -0.0341],\n",
              "           [-0.0329, -0.0329, -0.0252]],\n",
              " \n",
              "          [[-0.0376, -0.0309,  0.0263],\n",
              "           [-0.0202,  0.0128,  0.0365],\n",
              "           [-0.0352,  0.0217, -0.0310]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0088, -0.0190,  0.0410],\n",
              "           [-0.0087, -0.0031, -0.0190],\n",
              "           [ 0.0158, -0.0050, -0.0242]],\n",
              " \n",
              "          [[ 0.0350, -0.0255,  0.0082],\n",
              "           [ 0.0163,  0.0016,  0.0385],\n",
              "           [-0.0118, -0.0011, -0.0102]],\n",
              " \n",
              "          [[ 0.0137, -0.0386, -0.0310],\n",
              "           [ 0.0266,  0.0255, -0.0200],\n",
              "           [ 0.0358, -0.0053,  0.0013]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0125, -0.0228, -0.0130],\n",
              "           [ 0.0090, -0.0070,  0.0374],\n",
              "           [-0.0229, -0.0246,  0.0301]],\n",
              " \n",
              "          [[ 0.0225,  0.0061, -0.0150],\n",
              "           [-0.0344, -0.0205, -0.0249],\n",
              "           [ 0.0082, -0.0206,  0.0154]],\n",
              " \n",
              "          [[-0.0321,  0.0231, -0.0072],\n",
              "           [ 0.0368,  0.0208, -0.0140],\n",
              "           [-0.0207, -0.0172, -0.0252]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.0340,  0.0092,  0.0060],\n",
              "           [-0.0109,  0.0288,  0.0029],\n",
              "           [ 0.0336,  0.0127,  0.0325]],\n",
              " \n",
              "          [[ 0.0121, -0.0153,  0.0029],\n",
              "           [ 0.0311, -0.0282,  0.0200],\n",
              "           [-0.0229, -0.0370,  0.0352]],\n",
              " \n",
              "          [[-0.0034, -0.0186,  0.0072],\n",
              "           [-0.0286, -0.0303,  0.0201],\n",
              "           [ 0.0233,  0.0303,  0.0354]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0010, -0.0230,  0.0076],\n",
              "           [-0.0005,  0.0330, -0.0108],\n",
              "           [ 0.0333, -0.0242, -0.0342]],\n",
              " \n",
              "          [[ 0.0061, -0.0146, -0.0218],\n",
              "           [-0.0310, -0.0345, -0.0091],\n",
              "           [-0.0230, -0.0257,  0.0239]],\n",
              " \n",
              "          [[ 0.0236,  0.0252, -0.0187],\n",
              "           [ 0.0224, -0.0048,  0.0146],\n",
              "           [ 0.0251,  0.0063, -0.0231]]],\n",
              " \n",
              " \n",
              "         [[[-0.0251, -0.0176,  0.0097],\n",
              "           [-0.0314, -0.0353,  0.0293],\n",
              "           [ 0.0064, -0.0135, -0.0412]],\n",
              " \n",
              "          [[-0.0018,  0.0227, -0.0166],\n",
              "           [ 0.0381,  0.0320, -0.0014],\n",
              "           [ 0.0301,  0.0397,  0.0179]],\n",
              " \n",
              "          [[-0.0352,  0.0283,  0.0072],\n",
              "           [ 0.0407,  0.0181,  0.0123],\n",
              "           [-0.0151, -0.0165, -0.0304]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0303, -0.0242,  0.0014],\n",
              "           [-0.0088,  0.0416, -0.0374],\n",
              "           [-0.0276, -0.0146, -0.0200]],\n",
              " \n",
              "          [[-0.0128,  0.0096,  0.0341],\n",
              "           [ 0.0308,  0.0292, -0.0104],\n",
              "           [ 0.0299,  0.0323, -0.0377]],\n",
              " \n",
              "          [[-0.0048,  0.0412, -0.0163],\n",
              "           [-0.0299, -0.0084,  0.0275],\n",
              "           [ 0.0031,  0.0064, -0.0156]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0018, -0.0234,  0.0275],\n",
              "           [-0.0415,  0.0358,  0.0305],\n",
              "           [ 0.0247,  0.0065, -0.0214]],\n",
              " \n",
              "          [[-0.0098,  0.0385,  0.0350],\n",
              "           [ 0.0273, -0.0060,  0.0270],\n",
              "           [ 0.0362,  0.0136,  0.0266]],\n",
              " \n",
              "          [[ 0.0208,  0.0271,  0.0367],\n",
              "           [-0.0146, -0.0394, -0.0005],\n",
              "           [ 0.0247, -0.0052,  0.0084]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0252,  0.0049, -0.0350],\n",
              "           [ 0.0337, -0.0221, -0.0310],\n",
              "           [-0.0037,  0.0373, -0.0402]],\n",
              " \n",
              "          [[ 0.0016,  0.0114,  0.0322],\n",
              "           [-0.0231, -0.0032,  0.0298],\n",
              "           [-0.0322, -0.0246, -0.0024]],\n",
              " \n",
              "          [[ 0.0028, -0.0181, -0.0158],\n",
              "           [-0.0380,  0.0349, -0.0359],\n",
              "           [ 0.0371,  0.0349,  0.0337]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 7.9995e-04, -8.2050e-03,  4.7489e-04,  9.8896e-03,  2.1192e-02,\n",
              "         -3.0914e-02, -2.9140e-02, -2.1454e-03,  3.6319e-02,  3.6146e-02,\n",
              "          2.7437e-02, -3.8418e-02,  2.8275e-02, -3.3841e-02, -3.1366e-02,\n",
              "          5.5276e-03,  4.0233e-02,  2.4465e-02, -3.2542e-02,  1.6268e-02,\n",
              "          1.8786e-02, -3.1184e-02,  3.7653e-02,  2.8621e-02, -3.4496e-02,\n",
              "         -5.7803e-03,  1.2839e-02,  1.9036e-03,  4.1487e-02,  1.6559e-02,\n",
              "          1.2601e-02,  2.7055e-02,  2.5425e-02,  1.7249e-02, -3.4847e-02,\n",
              "          1.1134e-02,  1.0319e-02, -4.4199e-03, -1.8456e-02,  9.0506e-03,\n",
              "          1.3654e-02,  2.8227e-04, -1.5868e-02, -9.3285e-03,  2.2925e-02,\n",
              "         -1.2430e-02, -3.2975e-02,  2.7912e-02, -1.6266e-02,  1.3741e-02,\n",
              "          2.1017e-02, -1.3261e-02, -2.9849e-03, -1.9145e-02, -1.9421e-02,\n",
              "         -7.1529e-03,  9.2627e-03,  2.0021e-02, -3.1299e-02, -2.9435e-02,\n",
              "          1.1463e-02,  1.8660e-02, -6.2565e-03, -1.8103e-02, -1.9647e-02,\n",
              "         -7.3529e-03,  1.4036e-02, -4.0197e-02,  3.8888e-02, -4.1005e-02,\n",
              "         -4.0674e-02, -3.2546e-02, -9.9961e-03,  2.8832e-02,  1.6998e-02,\n",
              "          3.6370e-02,  1.2154e-02, -3.1691e-02, -1.6168e-02,  1.3622e-02,\n",
              "         -3.4935e-02, -3.8866e-02, -2.3471e-02, -2.7516e-02, -5.0242e-05,\n",
              "          2.3891e-02,  4.1296e-02, -3.3169e-02, -7.7490e-03,  1.6585e-02,\n",
              "         -2.3455e-02, -4.1347e-02,  1.5350e-02, -1.0657e-02, -3.5975e-02,\n",
              "          3.5864e-02,  3.0484e-02, -3.0826e-02,  2.0672e-04,  1.7404e-02,\n",
              "          3.4114e-02, -2.2015e-02,  6.8643e-03,  3.7427e-02,  3.7512e-02,\n",
              "         -2.7411e-02,  2.2896e-02, -4.5343e-03, -3.9893e-02, -3.6947e-02,\n",
              "          3.4547e-02, -1.7698e-02,  3.1787e-02, -1.4921e-02, -3.0421e-02,\n",
              "          3.4063e-02, -1.0825e-02,  3.0603e-02,  3.6270e-02, -1.0600e-03,\n",
              "          9.1221e-03, -4.1036e-03,  6.4002e-03, -2.2245e-02,  1.8440e-02,\n",
              "         -4.8366e-03, -3.3375e-02,  2.0538e-02], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0669,  0.0606, -0.0369,  ..., -0.0103, -0.0273,  0.0435],\n",
              "         [-0.0317, -0.0085,  0.0626,  ...,  0.0740,  0.0801,  0.0513],\n",
              "         [ 0.0433,  0.0738,  0.0702,  ..., -0.0001,  0.0440, -0.0488],\n",
              "         ...,\n",
              "         [ 0.0399,  0.0236, -0.0442,  ..., -0.0594, -0.0436,  0.0816],\n",
              "         [-0.0226, -0.0873, -0.0637,  ..., -0.0785, -0.0832,  0.0881],\n",
              "         [ 0.0566, -0.0189, -0.0201,  ..., -0.0664,  0.0309,  0.0296]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 5.5541e-02, -6.5252e-02,  3.0103e-02,  2.5709e-02,  5.9947e-02,\n",
              "         -2.8269e-02, -6.3372e-02,  2.1006e-03, -1.2369e-02,  7.9474e-02,\n",
              "          2.3858e-02, -6.3821e-02,  1.1570e-02,  6.9168e-02,  6.4612e-02,\n",
              "          7.2855e-02, -4.0065e-02,  3.7713e-02, -3.9230e-02,  6.4452e-02,\n",
              "          6.6262e-02, -5.2183e-02,  4.8921e-02,  5.5817e-02, -6.4376e-03,\n",
              "          6.4285e-02, -7.2922e-02, -2.0332e-02,  8.0055e-02,  2.4145e-02,\n",
              "          5.8709e-02,  6.2856e-03, -7.3113e-02,  1.3782e-02,  8.2274e-02,\n",
              "          5.5279e-02,  3.7474e-03,  1.1261e-02,  8.4932e-02,  6.9513e-02,\n",
              "          4.8601e-02,  8.1925e-02,  6.5740e-02,  3.9768e-02,  6.9597e-02,\n",
              "          7.3059e-02,  7.2778e-03, -5.2036e-02,  5.4132e-02, -6.6146e-02,\n",
              "          7.6638e-03,  6.6770e-02,  1.9515e-02, -3.4599e-02, -2.8226e-02,\n",
              "         -7.4174e-03,  2.4227e-02,  3.8252e-02,  4.4233e-02,  3.7616e-02,\n",
              "         -4.1763e-02,  1.3864e-02,  1.8421e-02,  7.1300e-02, -7.5323e-03,\n",
              "          6.8178e-02, -6.2100e-02, -2.3101e-02,  3.4811e-02,  5.0279e-03,\n",
              "         -6.8917e-02, -6.4952e-03, -3.0179e-02,  6.1854e-02,  4.5937e-02,\n",
              "          4.6103e-02, -5.9166e-02, -8.5852e-02,  8.7799e-02,  2.9924e-02,\n",
              "          9.9196e-03,  1.7086e-02,  6.1973e-03,  8.1519e-02,  7.0842e-02,\n",
              "          8.6414e-02,  4.4352e-02,  3.4622e-02,  4.8251e-02, -1.4352e-02,\n",
              "          5.9490e-02,  2.6033e-02,  3.3416e-02, -6.6101e-02, -2.7535e-02,\n",
              "         -5.8467e-02, -6.5770e-02,  2.7443e-02, -8.6428e-02, -4.9447e-03,\n",
              "          3.4870e-02,  7.7481e-02,  1.5821e-02, -1.2042e-02,  3.0816e-03,\n",
              "         -1.9457e-02,  7.9888e-02,  5.0466e-02, -5.3768e-02,  4.6688e-05,\n",
              "         -2.9354e-02,  1.5456e-02,  6.5582e-02,  6.7625e-02, -3.5047e-02,\n",
              "         -1.5785e-02, -1.1751e-02,  5.4667e-02, -4.2128e-02,  4.3903e-02,\n",
              "          4.3267e-02, -6.5653e-02, -4.6003e-02, -5.3550e-02,  7.7182e-02,\n",
              "          2.8343e-03,  2.7668e-02, -1.5955e-02, -4.1007e-02,  5.6705e-02,\n",
              "         -4.4326e-02, -7.9681e-02, -6.3411e-02,  5.9282e-02, -8.7456e-02,\n",
              "         -2.4403e-02, -2.2907e-02,  1.7214e-02,  5.3739e-02, -1.2786e-02,\n",
              "         -6.6303e-02, -5.0847e-02,  4.1950e-02,  1.4510e-02,  4.2338e-02,\n",
              "         -5.9002e-02, -1.6894e-02, -1.1808e-02, -1.8167e-02, -2.8866e-02,\n",
              "         -4.0419e-02, -3.4501e-02,  7.0719e-02,  2.9335e-02, -4.5498e-02,\n",
              "          7.3192e-02,  5.3335e-02,  7.5240e-02, -7.5497e-02, -1.9388e-02,\n",
              "          3.5955e-02,  3.9132e-02, -4.9999e-02, -8.2745e-02,  2.1614e-02,\n",
              "          1.9085e-02,  1.0468e-02,  7.9346e-02, -1.5946e-02, -2.8304e-02,\n",
              "         -3.3575e-02,  6.5800e-02, -1.0343e-02, -5.8688e-02,  8.2321e-02,\n",
              "         -7.6379e-02, -3.7723e-02,  4.8821e-02, -3.9232e-02,  8.0653e-03,\n",
              "         -5.2015e-02, -2.2355e-02,  4.7137e-02,  5.9520e-03,  6.8152e-02,\n",
              "          6.4953e-02, -1.8588e-02,  2.5887e-02, -9.9005e-03, -3.9040e-02,\n",
              "         -6.7554e-02,  4.2069e-02, -6.2856e-02, -5.3851e-02, -3.1813e-03,\n",
              "         -6.1837e-02, -1.3726e-02,  2.9008e-05, -5.6091e-02, -5.4251e-02,\n",
              "         -6.8256e-04, -3.6782e-02, -2.2019e-02, -4.3008e-02,  7.2935e-02,\n",
              "         -1.7139e-02, -6.9203e-02,  6.3341e-02,  7.5928e-03,  8.8161e-02,\n",
              "         -4.9021e-02,  2.9371e-02,  6.3150e-03, -2.5815e-03, -7.9492e-02,\n",
              "          5.8309e-02, -3.5943e-02, -4.1518e-03, -8.3942e-02, -7.3959e-03,\n",
              "         -4.9153e-02, -7.5744e-02,  2.1027e-02,  8.3804e-02, -4.2093e-02,\n",
              "          7.2984e-02, -3.7940e-03,  5.4575e-02,  1.1949e-02,  1.0670e-02,\n",
              "          7.4877e-02,  8.0900e-03,  7.9250e-02, -9.9988e-03,  5.0905e-02,\n",
              "          4.7060e-02,  1.7650e-02, -8.5711e-02, -7.9975e-02, -1.7631e-02,\n",
              "          7.5249e-02,  6.9790e-02,  6.5993e-02,  1.6050e-02,  5.9667e-02,\n",
              "          1.1731e-02,  4.7588e-02,  6.5770e-02, -8.5182e-02,  7.9258e-02,\n",
              "          3.3091e-02, -5.4390e-02, -1.9278e-02,  5.5917e-02, -8.2200e-02,\n",
              "          8.6929e-02, -7.8215e-02,  5.5488e-02,  9.7923e-03, -8.1553e-02,\n",
              "         -5.4872e-02,  2.0875e-02, -7.1876e-03,  7.1761e-02, -4.4321e-03,\n",
              "          1.4042e-02,  2.5993e-02,  5.1470e-02, -8.5375e-02,  5.2700e-02,\n",
              "         -1.4294e-02,  1.8038e-02,  7.9488e-02, -2.1170e-02, -1.5633e-02,\n",
              "         -3.3240e-02,  1.5856e-02,  4.7296e-02, -5.6266e-02,  2.7810e-02,\n",
              "          3.1276e-02,  1.6059e-02,  6.3461e-02, -5.1743e-02,  5.5984e-02,\n",
              "          7.9653e-02, -5.2561e-03, -4.4313e-02,  8.1550e-02, -4.3359e-02,\n",
              "          6.1736e-02, -7.1292e-02, -3.2534e-02, -7.3540e-02,  8.7997e-02,\n",
              "          4.3962e-02,  1.6745e-03, -3.0874e-02,  1.0413e-02, -2.3343e-02,\n",
              "         -4.8775e-02, -2.3105e-03, -1.6917e-02,  3.6604e-02,  2.8211e-02,\n",
              "          3.5067e-02,  4.3093e-02, -4.8593e-02,  6.5079e-02,  3.7756e-02,\n",
              "          4.5614e-03, -1.6739e-02,  6.9186e-02,  1.7706e-02, -4.1984e-03,\n",
              "          6.8218e-02, -4.3123e-02, -8.1128e-02,  2.7422e-02, -6.1929e-02,\n",
              "         -3.0041e-02, -7.3776e-02, -4.4068e-03,  6.1759e-02,  7.5272e-02,\n",
              "          1.6613e-02, -4.4775e-02,  7.0943e-02, -5.5239e-02, -3.1218e-02,\n",
              "         -7.2488e-02, -1.5398e-02,  5.1476e-02, -8.0114e-02,  8.3923e-02,\n",
              "          4.0561e-02, -1.4254e-02, -8.4194e-02, -1.5340e-02,  8.8678e-03,\n",
              "         -3.9968e-02, -1.1684e-02, -4.9997e-02,  8.2712e-02, -1.7072e-02,\n",
              "         -3.9761e-03, -4.7802e-02, -9.9360e-04, -7.1742e-03, -5.5121e-02,\n",
              "         -4.9476e-03,  8.1722e-02, -1.3878e-02,  5.0494e-02,  7.3241e-02,\n",
              "          4.5968e-02, -5.2797e-03,  6.1257e-02,  8.1994e-02, -4.6918e-02,\n",
              "          1.5975e-02,  6.7844e-02,  7.4918e-02, -1.7422e-02, -2.8493e-02,\n",
              "          3.8835e-02,  2.1951e-02, -4.5851e-02,  3.5673e-02,  7.5535e-02,\n",
              "         -8.4374e-02,  7.3117e-02,  5.3058e-02, -8.1467e-02, -4.4217e-03,\n",
              "          4.1001e-02, -2.8245e-02, -5.1909e-02,  3.5049e-02,  1.1002e-02,\n",
              "         -5.1946e-03, -6.0938e-02,  2.6904e-02, -4.3020e-02,  8.1517e-02,\n",
              "         -7.5634e-02, -5.8307e-02, -7.6853e-03, -2.5411e-02,  9.3211e-03,\n",
              "         -3.1811e-02, -7.2253e-02,  7.0429e-02,  5.0269e-02, -4.4591e-02,\n",
              "          1.3700e-02,  4.4693e-03, -3.1066e-02,  3.6228e-02, -3.2255e-02,\n",
              "          6.7647e-02,  4.9783e-04,  6.3790e-02,  2.5815e-02, -4.9098e-02,\n",
              "          1.0836e-02,  4.6585e-02, -2.6398e-02,  2.0618e-02,  8.0148e-02,\n",
              "          7.1552e-02,  1.6120e-02, -2.7089e-02,  2.7186e-02,  5.5720e-02,\n",
              "          6.7823e-02,  1.3235e-02,  2.3505e-02,  1.1666e-02,  1.8697e-03,\n",
              "          3.0897e-02, -8.4495e-02, -2.8751e-02,  4.6426e-02,  6.7078e-02,\n",
              "          1.5096e-02,  9.2711e-03,  2.8333e-02,  6.0933e-02, -3.1429e-02,\n",
              "          2.8600e-02, -4.3527e-02,  2.3854e-02, -7.7127e-02,  8.5576e-02,\n",
              "          6.6313e-02,  5.5283e-02,  3.3145e-02, -8.2371e-02, -1.7501e-03,\n",
              "          3.8807e-02, -4.5415e-02,  3.8096e-02, -1.8985e-02, -7.0318e-02,\n",
              "         -7.2868e-02,  6.4196e-02,  6.0270e-02,  5.6261e-02,  4.6082e-02,\n",
              "         -4.8016e-02, -5.6921e-03, -3.3081e-02, -2.1159e-02, -1.6221e-03,\n",
              "         -3.9145e-02, -3.8771e-02, -6.1356e-02, -9.7302e-03,  7.9104e-02,\n",
              "         -6.1393e-03, -2.9967e-02,  1.5921e-02,  5.9512e-02, -1.6489e-02,\n",
              "          7.5135e-02,  2.2924e-02, -6.2020e-02, -5.4187e-02, -5.0023e-03,\n",
              "          2.7379e-02,  4.9657e-02, -6.5054e-02,  6.5520e-02,  8.2673e-02,\n",
              "          6.2627e-02,  2.3812e-02, -4.3457e-02,  3.1012e-02,  2.4830e-02,\n",
              "          8.4730e-02, -4.2171e-02,  4.6807e-02, -1.5299e-02,  1.2690e-02,\n",
              "          5.7441e-02, -4.4818e-03,  2.8566e-02,  3.7825e-02, -2.4897e-02,\n",
              "          3.4317e-02, -2.8204e-02,  6.1761e-02, -5.6684e-02,  4.6887e-02,\n",
              "          3.8639e-02,  2.3370e-03, -7.2865e-02,  2.2700e-02,  5.1345e-02,\n",
              "         -5.7375e-02,  3.1857e-02,  3.8178e-02,  8.2078e-02, -1.1952e-02,\n",
              "         -3.0442e-02,  1.5398e-02,  5.7918e-03, -7.1066e-02,  5.8955e-03,\n",
              "          8.5897e-02, -4.3339e-02], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0234, -0.0298,  0.0393,  ..., -0.0235, -0.0415, -0.0190],\n",
              "         [-0.0420,  0.0076,  0.0197,  ..., -0.0125,  0.0092, -0.0268],\n",
              "         [ 0.0313,  0.0082,  0.0423,  ..., -0.0314, -0.0071,  0.0295],\n",
              "         ...,\n",
              "         [ 0.0014, -0.0077, -0.0048,  ..., -0.0386, -0.0162,  0.0360],\n",
              "         [-0.0437,  0.0080,  0.0382,  ...,  0.0186, -0.0148, -0.0395],\n",
              "         [ 0.0098, -0.0046, -0.0332,  ..., -0.0154,  0.0316,  0.0057]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0384,  0.0260,  0.0387,  0.0117, -0.0050,  0.0156,  0.0245, -0.0414,\n",
              "          0.0390,  0.0020,  0.0073,  0.0215,  0.0296,  0.0150,  0.0055,  0.0309,\n",
              "         -0.0210, -0.0087, -0.0012,  0.0146, -0.0422,  0.0056,  0.0047,  0.0203,\n",
              "         -0.0258,  0.0282, -0.0147,  0.0015, -0.0206,  0.0265, -0.0277, -0.0105,\n",
              "         -0.0150,  0.0135,  0.0152,  0.0057, -0.0022, -0.0049, -0.0244, -0.0345,\n",
              "         -0.0034, -0.0014,  0.0107,  0.0192,  0.0030, -0.0256,  0.0108,  0.0152,\n",
              "         -0.0215, -0.0311,  0.0184,  0.0021, -0.0420, -0.0437, -0.0148,  0.0367,\n",
              "         -0.0213,  0.0061, -0.0431, -0.0066, -0.0412, -0.0073, -0.0215,  0.0276,\n",
              "          0.0346, -0.0197,  0.0334,  0.0246,  0.0139,  0.0171, -0.0228, -0.0006,\n",
              "         -0.0099, -0.0047, -0.0344, -0.0091, -0.0256,  0.0127,  0.0071,  0.0217,\n",
              "          0.0128, -0.0424, -0.0172, -0.0069,  0.0071, -0.0249,  0.0020,  0.0369,\n",
              "         -0.0363,  0.0050, -0.0070, -0.0174,  0.0326, -0.0225,  0.0160, -0.0387,\n",
              "          0.0270, -0.0035, -0.0155, -0.0045,  0.0281,  0.0009,  0.0142, -0.0042,\n",
              "         -0.0120,  0.0148,  0.0198,  0.0159,  0.0262,  0.0317,  0.0246,  0.0125,\n",
              "          0.0397,  0.0100,  0.0055,  0.0083,  0.0122, -0.0245, -0.0122,  0.0338,\n",
              "          0.0117, -0.0068,  0.0430,  0.0296,  0.0218,  0.0392,  0.0123, -0.0034,\n",
              "         -0.0159, -0.0258,  0.0024, -0.0425,  0.0405, -0.0065,  0.0019, -0.0421,\n",
              "         -0.0026,  0.0157, -0.0022,  0.0080, -0.0080,  0.0170,  0.0087, -0.0427,\n",
              "         -0.0172, -0.0315, -0.0092,  0.0389, -0.0376, -0.0171, -0.0416,  0.0145,\n",
              "          0.0179,  0.0440, -0.0311,  0.0206,  0.0003, -0.0012, -0.0145,  0.0061,\n",
              "         -0.0427,  0.0402,  0.0064, -0.0399,  0.0005, -0.0243, -0.0218,  0.0223,\n",
              "          0.0417,  0.0389,  0.0040, -0.0292, -0.0192, -0.0182,  0.0365, -0.0151,\n",
              "          0.0230,  0.0062,  0.0019,  0.0007, -0.0091, -0.0019, -0.0113,  0.0396,\n",
              "          0.0169, -0.0028, -0.0068, -0.0272, -0.0131, -0.0211, -0.0301, -0.0371,\n",
              "          0.0018, -0.0282, -0.0034, -0.0398,  0.0185,  0.0160,  0.0038, -0.0367,\n",
              "         -0.0098, -0.0229,  0.0105, -0.0395,  0.0244,  0.0057,  0.0091,  0.0108,\n",
              "          0.0243,  0.0327,  0.0272,  0.0271,  0.0072, -0.0293,  0.0356, -0.0151,\n",
              "         -0.0142, -0.0401, -0.0175, -0.0096,  0.0251,  0.0373,  0.0246, -0.0412,\n",
              "          0.0246,  0.0239,  0.0081, -0.0432, -0.0354, -0.0113, -0.0297, -0.0303,\n",
              "         -0.0221, -0.0056,  0.0288, -0.0141, -0.0097,  0.0242, -0.0106, -0.0210,\n",
              "          0.0019,  0.0345, -0.0371,  0.0293,  0.0144,  0.0004,  0.0021, -0.0152,\n",
              "         -0.0045, -0.0258,  0.0184, -0.0089,  0.0435,  0.0139, -0.0284,  0.0423],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0616,  0.0267, -0.0307,  ...,  0.0329,  0.0302, -0.0295],\n",
              "         [ 0.0099, -0.0044, -0.0371,  ..., -0.0098,  0.0300, -0.0119],\n",
              "         [-0.0211,  0.0167,  0.0050,  ...,  0.0223,  0.0255,  0.0565],\n",
              "         ...,\n",
              "         [-0.0447,  0.0023,  0.0481,  ..., -0.0136,  0.0349, -0.0268],\n",
              "         [-0.0451, -0.0601,  0.0382,  ..., -0.0397, -0.0311, -0.0066],\n",
              "         [-0.0442, -0.0569, -0.0606,  ...,  0.0394,  0.0361,  0.0538]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0549,  0.0517,  0.0086,  0.0340, -0.0168,  0.0551, -0.0387, -0.0263,\n",
              "         -0.0469,  0.0505, -0.0593, -0.0391,  0.0145, -0.0098,  0.0245,  0.0531,\n",
              "          0.0416, -0.0128,  0.0022,  0.0335, -0.0547, -0.0440,  0.0499, -0.0035,\n",
              "          0.0194,  0.0087, -0.0359, -0.0109,  0.0578,  0.0566, -0.0486, -0.0437],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.1730, -0.1454, -0.1438, -0.1450,  0.0384,  0.0971,  0.0324, -0.0523,\n",
              "           0.1453, -0.1546, -0.1762, -0.0327,  0.0328, -0.0356, -0.0480, -0.0924,\n",
              "          -0.0933, -0.0716, -0.0482, -0.1510,  0.0532,  0.0737, -0.1260, -0.1117,\n",
              "           0.0540,  0.0138,  0.0084,  0.0255, -0.0176,  0.1061,  0.0569,  0.0068],\n",
              "         [ 0.0631, -0.0039,  0.0740, -0.0972,  0.0455,  0.1727, -0.1432,  0.1757,\n",
              "          -0.0093, -0.1102, -0.0237, -0.0681,  0.1409,  0.1456,  0.0921, -0.1354,\n",
              "          -0.0095, -0.1720,  0.0266,  0.1470, -0.0886,  0.0856,  0.0928, -0.1044,\n",
              "          -0.0731,  0.0142,  0.1244, -0.1550, -0.0917, -0.0540, -0.0962,  0.0902],\n",
              "         [-0.1020,  0.0574, -0.0551,  0.0053, -0.0463, -0.1319, -0.0722,  0.0598,\n",
              "          -0.1469, -0.1124,  0.1662, -0.1126,  0.0386,  0.1723,  0.1761,  0.0594,\n",
              "           0.0323, -0.1155, -0.1083, -0.1378, -0.0401,  0.1035, -0.1055, -0.0735,\n",
              "           0.0518,  0.1033,  0.1552, -0.0299, -0.1738,  0.0802,  0.1435,  0.0791],\n",
              "         [ 0.1755, -0.1142,  0.1755, -0.0410, -0.0801,  0.0010, -0.1083,  0.0201,\n",
              "          -0.1292,  0.0398,  0.0733, -0.0382,  0.0477, -0.1684,  0.1300, -0.0930,\n",
              "           0.1606,  0.1674, -0.0806, -0.0463, -0.0404,  0.0146,  0.1216,  0.0956,\n",
              "           0.0815,  0.0466,  0.1606,  0.0883,  0.0351,  0.0261,  0.1350,  0.0484],\n",
              "         [ 0.1205,  0.0413, -0.1513,  0.0719,  0.0770,  0.1660, -0.1307, -0.0847,\n",
              "          -0.0234,  0.1120, -0.0647,  0.1247, -0.1047,  0.1039, -0.0005, -0.1287,\n",
              "          -0.0165, -0.1686, -0.1424,  0.1361,  0.0065,  0.0956, -0.0679, -0.0521,\n",
              "          -0.0011,  0.0767,  0.0759, -0.0804, -0.1004, -0.0939,  0.1745,  0.0247],\n",
              "         [-0.0042, -0.0518,  0.1049, -0.0565,  0.0078, -0.1371,  0.0609, -0.0607,\n",
              "          -0.1622,  0.1571,  0.0036, -0.0574, -0.1300,  0.0170, -0.1649, -0.1720,\n",
              "           0.0175,  0.1111,  0.0990, -0.0604,  0.0112,  0.1227,  0.1430, -0.1435,\n",
              "           0.1143, -0.1055,  0.0984, -0.0520, -0.0181, -0.1221, -0.1693,  0.1249],\n",
              "         [-0.1729, -0.0549,  0.0157, -0.1169, -0.0138,  0.1741,  0.0433,  0.1406,\n",
              "          -0.1251, -0.0240, -0.0109, -0.1609,  0.0669,  0.0187, -0.0006, -0.0861,\n",
              "          -0.0535, -0.1117,  0.0461,  0.1546,  0.1550,  0.0833,  0.1570, -0.0684,\n",
              "          -0.0923,  0.0726,  0.0973, -0.0597, -0.0775,  0.0168,  0.0035, -0.1539],\n",
              "         [ 0.1545,  0.0736, -0.0890,  0.1639,  0.0301, -0.1358,  0.1236, -0.0656,\n",
              "          -0.0384, -0.0564,  0.1765,  0.0073,  0.0504,  0.0898, -0.0756, -0.0116,\n",
              "          -0.0217,  0.1229,  0.0332, -0.0265, -0.0438, -0.0786,  0.0057, -0.1313,\n",
              "          -0.0544, -0.0896,  0.0878,  0.1517,  0.0379, -0.0710, -0.0759, -0.0558],\n",
              "         [ 0.0014, -0.1275, -0.0624, -0.1719, -0.1180,  0.0116,  0.0355,  0.0672,\n",
              "          -0.1043, -0.1638,  0.1090,  0.1497,  0.0432, -0.0740, -0.0665, -0.0795,\n",
              "          -0.0925,  0.1666, -0.1363,  0.1025, -0.1476,  0.1046, -0.1372, -0.0431,\n",
              "           0.0827, -0.1075,  0.0926, -0.1295,  0.0116,  0.1067,  0.0504, -0.0774],\n",
              "         [-0.0418, -0.0819, -0.1684,  0.0198,  0.0734,  0.1613, -0.0075,  0.0104,\n",
              "          -0.0242, -0.1045, -0.1442, -0.0842,  0.0380, -0.0528,  0.1722, -0.0087,\n",
              "           0.1368, -0.1500,  0.1131, -0.0983,  0.1626,  0.1060, -0.1328, -0.0453,\n",
              "           0.0257, -0.1378, -0.1166,  0.0007, -0.1103,  0.1736, -0.0437, -0.1340]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0046,  0.1420,  0.1745, -0.0509,  0.0465,  0.1011, -0.0388,  0.1510,\n",
              "          0.1254, -0.0531], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(cnn_model,input_size=(1,28,28),device = \"cpu\",batch_size=1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZZm_MIUo-wz",
        "outputId": "f07e1270-d3ce-4397-8dd6-c6cb3e9ea221"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [1, 16, 28, 28]             160\n",
            "         MaxPool2d-2            [1, 16, 14, 14]               0\n",
            "       BatchNorm2d-3            [1, 16, 14, 14]              32\n",
            "            Conv2d-4            [1, 32, 14, 14]           4,640\n",
            "         MaxPool2d-5              [1, 32, 7, 7]               0\n",
            "            Conv2d-6              [1, 64, 7, 7]          18,496\n",
            "         MaxPool2d-7              [1, 64, 3, 3]               0\n",
            "       BatchNorm2d-8              [1, 64, 3, 3]             128\n",
            "            Conv2d-9             [1, 128, 3, 3]          73,856\n",
            "        MaxPool2d-10             [1, 128, 1, 1]               0\n",
            "           Linear-11                   [1, 512]          66,048\n",
            "           Linear-12                   [1, 256]         131,328\n",
            "           Linear-13                    [1, 32]           8,224\n",
            "           Linear-14                    [1, 10]             330\n",
            "================================================================\n",
            "Total params: 303,242\n",
            "Trainable params: 303,242\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.25\n",
            "Params size (MB): 1.16\n",
            "Estimated Total Size (MB): 1.41\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(params=cnn_model.parameters())"
      ],
      "metadata": {
        "id": "rdy6tCA2tIQR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(TensorDataset(x_train.float(),y_train),batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "W3NDz_A7uZ4D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "cnn_model = cnn_model.to(\"cuda\")\n",
        "for epoch in range(n_epochs):\n",
        "  training_loss = 0.0\n",
        "  for batch, target in train_loader:\n",
        "    batch = batch.to(\"cuda\")\n",
        "    target = target.to(\"cuda\")\n",
        "\n",
        "    opt.zero_grad()\n",
        "    output = cnn_model(batch)\n",
        "    #probs = torch.softmax(output,dim=1)\n",
        "    loss = F.cross_entropy(output, target)\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    training_loss += loss.item()\n",
        "\n",
        "  if (epoch+1)%5 ==0:\n",
        "    print(f\"Training loss after {epoch+1} is : {training_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r83B9sEut1a",
        "outputId": "f19f9df1-e028-4c53-e410-2a351d9ccd25"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss after 5 is : 25.873621437465772\n",
            "Training loss after 10 is : 13.050845159384153\n",
            "Training loss after 15 is : 10.858933879230449\n",
            "Training loss after 20 is : 7.971546850550247\n",
            "Training loss after 25 is : 7.610025110563079\n",
            "Training loss after 30 is : 5.760909594083098\n",
            "Training loss after 35 is : 5.40191063415261\n",
            "Training loss after 40 is : 3.5901967466724862\n",
            "Training loss after 45 is : 4.414646754060712\n",
            "Training loss after 50 is : 2.9493699161900757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_test = cnn_model(x_test.float().to(\"cuda\")).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "cEVdMpXU0MEj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds_test,axis = 1)"
      ],
      "metadata": {
        "id": "hqaM2OBs0ggD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "UoGNklNI0kGH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(preds, y_test.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "5TvxCGe302eC",
        "outputId": "e61e101a-c5e0-4a75-c52d-28bd46ede120"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0    0     1     2     3    4    5    6     7    8    9\n",
              "row_0                                                      \n",
              "0      978     0     0     0    0    1    3     0    1    0\n",
              "1        0  1133     0     0    0    0    1     2    0    2\n",
              "2        2     0  1028     0    1    0    1     2    0    0\n",
              "3        0     0     0  1003    0    5    0     0    0    0\n",
              "4        0     0     0     0  969    0    0     0    0    4\n",
              "5        0     0     0     5    0  883    1     0    1    1\n",
              "6        0     0     0     0    3    1  950     0    0    0\n",
              "7        0     2     3     2    2    0    0  1022    0    0\n",
              "8        0     0     1     0    1    0    2     0  971    3\n",
              "9        0     0     0     0    6    2    0     2    1  999"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5b6cb85-98e8-4272-9488-c4aafe052c55\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1133</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1028</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1003</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>883</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>950</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1022</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>971</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5b6cb85-98e8-4272-9488-c4aafe052c55')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5b6cb85-98e8-4272-9488-c4aafe052c55 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5b6cb85-98e8-4272-9488-c4aafe052c55');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPOerX-d0-j7"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}