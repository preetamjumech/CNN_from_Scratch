{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNesjDaO1xZxfTBSaPD02q1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/CNN_from_Scratch/blob/main/Preetam_Saha_CNN_MNIST_practice_24_09_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq9_jrjug95I",
        "outputId": "3d4006ef-81d1-484d-b381-6f7a1bafe85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-24 09:22:21--  https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/training.pt [following]\n",
            "--2022-09-24 09:22:21--  https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47520431 (45M) [application/octet-stream]\n",
            "Saving to: ‘training.pt.1’\n",
            "\n",
            "training.pt.1       100%[===================>]  45.32M   203MB/s    in 0.2s    \n",
            "\n",
            "2022-09-24 09:22:21 (203 MB/s) - ‘training.pt.1’ saved [47520431/47520431]\n",
            "\n",
            "--2022-09-24 09:22:21--  https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/test.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/test.pt [following]\n",
            "--2022-09-24 09:22:22--  https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/test.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7920431 (7.6M) [application/octet-stream]\n",
            "Saving to: ‘test.pt.1’\n",
            "\n",
            "test.pt.1           100%[===================>]   7.55M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-09-24 09:22:22 (82.6 MB/s) - ‘test.pt.1’ saved [7920431/7920431]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/test.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchsummary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, RMSprop\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "acSVKgdOhR9h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train) , (x_test,y_test) = torch.load(\"training.pt\"), torch.load(\"test.pt\")"
      ],
      "metadata": {
        "id": "iHNltoCmhuGv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape , y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKgyVHxljpTq",
        "outputId": "49173f75-e819-45b8-fc6b-c25eff254cb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([60000]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1,1,28,28)\n",
        "x_test = x_test.reshape(-1,1,28,28)"
      ],
      "metadata": {
        "id": "mU5KVzPBjw9z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV0-hGjtlTb4",
        "outputId": "6d6a1a3b-6ccd-44b0-8cdc-eabba435dfaf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "imDujv6rkB-6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 3\n",
        "Image.fromarray(x_train[idx,0,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "c1mpMpPMkInl",
        "outputId": "16f32529-b294-41a8-cd57-ccd8e1be2c3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F55E246B290>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65gA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fgCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=200\n",
        "Image.fromarray(x_train[idx,0,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "Pv2QQJ-xlfuU",
        "outputId": "139455b8-2e27-4834-b00b-fcfd21c1f5fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F55E23EAE90>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfklEQVR4nMWMyw1CQQwDY0t0AW0gqONBVTQCrw4+gjqgilUSrrtIjsQFfEo8Gpv9N6tL7oaC3b1ZR0oIYpYwI6MyearMVBAEoeD1VpjPV2FaFqbhG3NMeBz6pQF6MBZi1kBwq2a9eTsq807wocx989a9o2nER9FlOZ0nCX+TN1oBLyyKsf7OAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=300\n",
        "Image.fromarray(x_train[idx,0,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "_lyhfp1xltKi",
        "outputId": "0d144ad7-f191-4094-dbf3-9cd6f0dcb852"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F55E23F28D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzklEQVR4nGNgGOyg691NF1xy0/79+/cCh5z9g38T/30QwybFv+Dvv3+7/23Bqm/Hvx3n//37YYxNrvrPOUH9f/8asGp8+k+bYem/+WzYJd+Ka72+JYHdqVf/ZV75boRdjsHmJ5qFTEjsI5MYGJQ5cOhkWPLv879IHHIWPzcavj6FXY796k8jhivfNbHaaae59BwDAzs3Vp1X/skxMFz5Z4JNjuX1VQ4G1c8fFbBJCn84wcJ68F8ddge9+Hfl1r/D/NglXW78+7eMD7scVQEAfcJRtn7OEhMAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MNIST_CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=16, kernel_size=3, padding=1 ) #in_channel = channel, out_channels=no of filters, kernel_Size = filter size\n",
        "    self.conv2 = nn.Conv2d(in_channels=16,out_channels=32, kernel_size=3, padding=1 )\n",
        "    self.conv3 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=3, padding=1 )\n",
        "    self.conv4 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=3, padding=1 )\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=16)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=32)\n",
        "    self.bn3 = nn.BatchNorm2d(num_features=64)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride = 2) #by pooling only reduction happenes, stride = 2 means jump of 2 pixels\n",
        "    self.h1 = nn.Linear(in_features=1*1*128, out_features= 512)\n",
        "    self.h2 = nn.Linear(in_features=512, out_features= 256)\n",
        "    self.h3 = nn.Linear(in_features= 256, out_features= 32)\n",
        "    self.out = nn.Linear(in_features = 32, out_features=10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn3(x)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.pool(x)\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.view(x.size()[0],-1)\n",
        "    #print(x.size())\n",
        "\n",
        "    x = F.relu(self.h1(x))\n",
        "    x = F.relu(self.h2(x))\n",
        "    x = F.relu(self.h3(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "BIm9_FvZwg0C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = MNIST_CNN()"
      ],
      "metadata": {
        "id": "ANWhDIS6qafj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(cnn_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuE8QLehqnUN",
        "outputId": "81d94c8f-257d-47a1-995b-3e47ed9cb3ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[[[ 0.1611, -0.2510,  0.0426],\n",
              "           [ 0.2098,  0.2426, -0.2421],\n",
              "           [-0.1161, -0.1590, -0.0639]]],\n",
              " \n",
              " \n",
              "         [[[ 0.2271, -0.0780, -0.2621],\n",
              "           [-0.0097,  0.0516,  0.1884],\n",
              "           [ 0.0849, -0.2967, -0.2091]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0325,  0.3007, -0.1510],\n",
              "           [-0.2614,  0.1871, -0.0744],\n",
              "           [ 0.2829, -0.2083,  0.3055]]],\n",
              " \n",
              " \n",
              "         [[[-0.2672, -0.2952,  0.0706],\n",
              "           [ 0.1891, -0.1290, -0.1860],\n",
              "           [-0.1478,  0.3087,  0.0038]]],\n",
              " \n",
              " \n",
              "         [[[ 0.2971,  0.2812,  0.1297],\n",
              "           [ 0.0264, -0.0066, -0.1679],\n",
              "           [-0.0712,  0.3110,  0.0675]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1692, -0.0034, -0.3161],\n",
              "           [ 0.1067,  0.0094, -0.0882],\n",
              "           [-0.1725, -0.0043, -0.1951]]],\n",
              " \n",
              " \n",
              "         [[[-0.1159, -0.0849, -0.1509],\n",
              "           [-0.0297,  0.1176,  0.1689],\n",
              "           [ 0.2235, -0.1152, -0.0324]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1271,  0.1267, -0.2997],\n",
              "           [ 0.2824, -0.0836, -0.3123],\n",
              "           [ 0.2410,  0.0935,  0.2038]]],\n",
              " \n",
              " \n",
              "         [[[-0.1453, -0.0874,  0.0037],\n",
              "           [ 0.0305,  0.1882,  0.2263],\n",
              "           [ 0.2319,  0.1459,  0.1615]]],\n",
              " \n",
              " \n",
              "         [[[-0.0775, -0.3318,  0.1818],\n",
              "           [ 0.2243,  0.2290,  0.0013],\n",
              "           [-0.1740,  0.1881, -0.1039]]],\n",
              " \n",
              " \n",
              "         [[[-0.2250,  0.1701, -0.0865],\n",
              "           [-0.1092, -0.1882, -0.1775],\n",
              "           [-0.1244,  0.1740, -0.2206]]],\n",
              " \n",
              " \n",
              "         [[[ 0.2345,  0.1210, -0.0122],\n",
              "           [-0.1999,  0.2288,  0.1272],\n",
              "           [-0.1933,  0.0158, -0.1371]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0334,  0.2662, -0.2124],\n",
              "           [ 0.3061, -0.0599, -0.1501],\n",
              "           [-0.2610,  0.0435, -0.2557]]],\n",
              " \n",
              " \n",
              "         [[[-0.0800,  0.0736, -0.0935],\n",
              "           [ 0.2138, -0.0566,  0.0364],\n",
              "           [ 0.3187,  0.2556, -0.0530]]],\n",
              " \n",
              " \n",
              "         [[[-0.1361,  0.2648,  0.2065],\n",
              "           [-0.0016, -0.2741, -0.0852],\n",
              "           [ 0.2428, -0.2315, -0.0588]]],\n",
              " \n",
              " \n",
              "         [[[ 0.3081,  0.2536, -0.0103],\n",
              "           [-0.1681,  0.0331,  0.2084],\n",
              "           [ 0.2278, -0.2185,  0.1408]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1689,  0.1749, -0.1746,  0.2019,  0.1777, -0.1441, -0.1397, -0.0058,\n",
              "          0.0198, -0.3007, -0.1771, -0.1866, -0.0008, -0.0183, -0.2859,  0.2814],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.0324, -0.0143, -0.0329],\n",
              "           [-0.0221, -0.0778,  0.0389],\n",
              "           [-0.0440, -0.0645,  0.0225]],\n",
              " \n",
              "          [[-0.0661,  0.0415, -0.0493],\n",
              "           [-0.0114, -0.0399,  0.0713],\n",
              "           [-0.0155, -0.0475, -0.0788]],\n",
              " \n",
              "          [[-0.0428,  0.0533, -0.0814],\n",
              "           [-0.0180,  0.0707, -0.0447],\n",
              "           [-0.0774, -0.0563,  0.0429]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0325, -0.0030, -0.0277],\n",
              "           [ 0.0145,  0.0693, -0.0196],\n",
              "           [-0.0695, -0.0761, -0.0284]],\n",
              " \n",
              "          [[ 0.0101,  0.0453, -0.0200],\n",
              "           [ 0.0259, -0.0083,  0.0743],\n",
              "           [ 0.0364,  0.0092,  0.0100]],\n",
              " \n",
              "          [[ 0.0326, -0.0751,  0.0193],\n",
              "           [ 0.0164, -0.0721,  0.0571],\n",
              "           [-0.0209,  0.0200,  0.0478]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0710,  0.0467,  0.0066],\n",
              "           [-0.0108,  0.0778,  0.0633],\n",
              "           [-0.0151,  0.0765,  0.0108]],\n",
              " \n",
              "          [[ 0.0736, -0.0437, -0.0520],\n",
              "           [-0.0794,  0.0202,  0.0040],\n",
              "           [-0.0817, -0.0085,  0.0261]],\n",
              " \n",
              "          [[ 0.0803,  0.0348, -0.0719],\n",
              "           [ 0.0541, -0.0130, -0.0394],\n",
              "           [-0.0726,  0.0348,  0.0533]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0050, -0.0273, -0.0578],\n",
              "           [ 0.0322, -0.0735, -0.0097],\n",
              "           [-0.0731, -0.0342,  0.0624]],\n",
              " \n",
              "          [[-0.0695, -0.0187, -0.0625],\n",
              "           [-0.0421, -0.0699,  0.0431],\n",
              "           [ 0.0003, -0.0827, -0.0746]],\n",
              " \n",
              "          [[ 0.0557, -0.0479,  0.0308],\n",
              "           [ 0.0155,  0.0335,  0.0204],\n",
              "           [-0.0360,  0.0046, -0.0170]]],\n",
              " \n",
              " \n",
              "         [[[-0.0137, -0.0549, -0.0489],\n",
              "           [ 0.0725, -0.0783,  0.0683],\n",
              "           [ 0.0496,  0.0799,  0.0686]],\n",
              " \n",
              "          [[ 0.0502, -0.0059, -0.0505],\n",
              "           [-0.0543, -0.0597, -0.0548],\n",
              "           [ 0.0491,  0.0491, -0.0550]],\n",
              " \n",
              "          [[-0.0106,  0.0729,  0.0246],\n",
              "           [ 0.0827, -0.0739, -0.0696],\n",
              "           [ 0.0667, -0.0156, -0.0612]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0578,  0.0264, -0.0193],\n",
              "           [ 0.0350,  0.0547, -0.0720],\n",
              "           [-0.0361, -0.0412, -0.0720]],\n",
              " \n",
              "          [[-0.0451, -0.0153, -0.0757],\n",
              "           [-0.0045, -0.0528, -0.0371],\n",
              "           [ 0.0007,  0.0616,  0.0489]],\n",
              " \n",
              "          [[-0.0778,  0.0534, -0.0763],\n",
              "           [ 0.0168,  0.0615, -0.0562],\n",
              "           [-0.0268, -0.0136,  0.0626]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[ 0.0326, -0.0127,  0.0511],\n",
              "           [-0.0247, -0.0211, -0.0398],\n",
              "           [-0.0560, -0.0259,  0.0594]],\n",
              " \n",
              "          [[-0.0728,  0.0546, -0.0233],\n",
              "           [-0.0240, -0.0563, -0.0740],\n",
              "           [ 0.0318, -0.0548,  0.0234]],\n",
              " \n",
              "          [[ 0.0715, -0.0349,  0.0070],\n",
              "           [-0.0235, -0.0374, -0.0177],\n",
              "           [-0.0056, -0.0476, -0.0818]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0136, -0.0508, -0.0633],\n",
              "           [ 0.0688, -0.0826, -0.0515],\n",
              "           [-0.0659, -0.0572, -0.0228]],\n",
              " \n",
              "          [[ 0.0024,  0.0252,  0.0417],\n",
              "           [ 0.0103,  0.0739, -0.0257],\n",
              "           [-0.0311,  0.0619, -0.0445]],\n",
              " \n",
              "          [[ 0.0189, -0.0545,  0.0827],\n",
              "           [ 0.0798,  0.0527,  0.0355],\n",
              "           [ 0.0732, -0.0660, -0.0085]]],\n",
              " \n",
              " \n",
              "         [[[-0.0446,  0.0351,  0.0538],\n",
              "           [ 0.0543, -0.0476, -0.0095],\n",
              "           [ 0.0293,  0.0049, -0.0068]],\n",
              " \n",
              "          [[-0.0244,  0.0434, -0.0152],\n",
              "           [ 0.0250,  0.0416,  0.0719],\n",
              "           [-0.0179, -0.0632,  0.0220]],\n",
              " \n",
              "          [[-0.0556, -0.0162, -0.0682],\n",
              "           [-0.0649,  0.0756, -0.0636],\n",
              "           [-0.0523, -0.0345, -0.0115]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0354, -0.0358,  0.0418],\n",
              "           [ 0.0218,  0.0652, -0.0108],\n",
              "           [-0.0135, -0.0216,  0.0741]],\n",
              " \n",
              "          [[-0.0162, -0.0029, -0.0071],\n",
              "           [ 0.0666, -0.0209,  0.0049],\n",
              "           [-0.0783, -0.0747, -0.0027]],\n",
              " \n",
              "          [[-0.0391,  0.0373, -0.0688],\n",
              "           [-0.0473, -0.0709, -0.0292],\n",
              "           [-0.0504,  0.0098, -0.0621]]],\n",
              " \n",
              " \n",
              "         [[[-0.0127,  0.0297, -0.0084],\n",
              "           [ 0.0093, -0.0146, -0.0259],\n",
              "           [-0.0045, -0.0287, -0.0544]],\n",
              " \n",
              "          [[ 0.0765, -0.0451, -0.0630],\n",
              "           [-0.0217,  0.0591,  0.0141],\n",
              "           [ 0.0585, -0.0103,  0.0131]],\n",
              " \n",
              "          [[ 0.0530,  0.0436, -0.0427],\n",
              "           [ 0.0548,  0.0007, -0.0195],\n",
              "           [-0.0216, -0.0443, -0.0442]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0002,  0.0373,  0.0665],\n",
              "           [-0.0664, -0.0667, -0.0694],\n",
              "           [ 0.0801,  0.0189, -0.0120]],\n",
              " \n",
              "          [[ 0.0327, -0.0661,  0.0493],\n",
              "           [ 0.0610, -0.0776,  0.0548],\n",
              "           [ 0.0306, -0.0806,  0.0601]],\n",
              " \n",
              "          [[ 0.0326, -0.0066,  0.0011],\n",
              "           [-0.0140,  0.0800,  0.0084],\n",
              "           [ 0.0246,  0.0013,  0.0045]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0829, -0.0239,  0.0726,  0.0566,  0.0334, -0.0061, -0.0596,  0.0589,\n",
              "         -0.0217,  0.0681, -0.0418, -0.0062,  0.0365, -0.0465, -0.0209, -0.0390,\n",
              "          0.0321,  0.0151,  0.0162, -0.0048, -0.0100,  0.0016,  0.0093,  0.0023,\n",
              "         -0.0704,  0.0456, -0.0107, -0.0536, -0.0368,  0.0167, -0.0025, -0.0024],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.0384, -0.0273,  0.0453],\n",
              "           [ 0.0552,  0.0113, -0.0174],\n",
              "           [ 0.0072, -0.0056, -0.0028]],\n",
              " \n",
              "          [[-0.0471, -0.0051, -0.0387],\n",
              "           [-0.0202, -0.0162, -0.0298],\n",
              "           [ 0.0481, -0.0289, -0.0042]],\n",
              " \n",
              "          [[-0.0310, -0.0362,  0.0404],\n",
              "           [-0.0297,  0.0107, -0.0401],\n",
              "           [ 0.0452, -0.0428, -0.0561]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0095,  0.0093, -0.0311],\n",
              "           [-0.0242,  0.0414, -0.0223],\n",
              "           [-0.0251, -0.0536, -0.0558]],\n",
              " \n",
              "          [[ 0.0069,  0.0087, -0.0045],\n",
              "           [-0.0579,  0.0188,  0.0334],\n",
              "           [ 0.0221,  0.0044,  0.0002]],\n",
              " \n",
              "          [[ 0.0051, -0.0077, -0.0495],\n",
              "           [-0.0298, -0.0288, -0.0428],\n",
              "           [ 0.0031,  0.0555, -0.0026]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0037, -0.0150, -0.0473],\n",
              "           [-0.0527, -0.0462, -0.0500],\n",
              "           [-0.0011,  0.0082, -0.0065]],\n",
              " \n",
              "          [[ 0.0510,  0.0414,  0.0421],\n",
              "           [ 0.0581,  0.0206, -0.0484],\n",
              "           [-0.0289, -0.0137,  0.0147]],\n",
              " \n",
              "          [[ 0.0317, -0.0177, -0.0240],\n",
              "           [-0.0207, -0.0095, -0.0178],\n",
              "           [-0.0153,  0.0362,  0.0186]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0587,  0.0471,  0.0165],\n",
              "           [ 0.0334,  0.0152, -0.0554],\n",
              "           [-0.0587,  0.0094, -0.0546]],\n",
              " \n",
              "          [[-0.0045, -0.0179,  0.0290],\n",
              "           [ 0.0272,  0.0475, -0.0427],\n",
              "           [ 0.0250,  0.0373, -0.0511]],\n",
              " \n",
              "          [[-0.0428, -0.0152, -0.0135],\n",
              "           [-0.0397,  0.0493, -0.0018],\n",
              "           [ 0.0210,  0.0577, -0.0432]]],\n",
              " \n",
              " \n",
              "         [[[-0.0476,  0.0374, -0.0108],\n",
              "           [-0.0088, -0.0406, -0.0334],\n",
              "           [-0.0050, -0.0107, -0.0013]],\n",
              " \n",
              "          [[-0.0584, -0.0016, -0.0238],\n",
              "           [-0.0470,  0.0472, -0.0178],\n",
              "           [ 0.0435,  0.0009, -0.0424]],\n",
              " \n",
              "          [[-0.0388, -0.0108,  0.0263],\n",
              "           [-0.0012, -0.0133,  0.0052],\n",
              "           [-0.0530,  0.0172, -0.0548]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0058,  0.0391, -0.0375],\n",
              "           [ 0.0488,  0.0313, -0.0134],\n",
              "           [-0.0131,  0.0515,  0.0287]],\n",
              " \n",
              "          [[-0.0040,  0.0382,  0.0330],\n",
              "           [-0.0415,  0.0050,  0.0012],\n",
              "           [ 0.0533,  0.0191, -0.0333]],\n",
              " \n",
              "          [[ 0.0462, -0.0159, -0.0061],\n",
              "           [ 0.0243, -0.0215, -0.0400],\n",
              "           [-0.0322, -0.0322, -0.0469]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.0308, -0.0568,  0.0113],\n",
              "           [ 0.0209, -0.0435, -0.0564],\n",
              "           [ 0.0516,  0.0542, -0.0277]],\n",
              " \n",
              "          [[-0.0403, -0.0092, -0.0193],\n",
              "           [ 0.0175, -0.0132, -0.0153],\n",
              "           [-0.0567, -0.0344,  0.0149]],\n",
              " \n",
              "          [[ 0.0479,  0.0587,  0.0232],\n",
              "           [ 0.0066,  0.0261, -0.0532],\n",
              "           [-0.0052, -0.0375, -0.0103]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0206, -0.0201, -0.0004],\n",
              "           [ 0.0077,  0.0518, -0.0216],\n",
              "           [-0.0156, -0.0172, -0.0014]],\n",
              " \n",
              "          [[-0.0125, -0.0108, -0.0158],\n",
              "           [ 0.0553, -0.0455,  0.0245],\n",
              "           [ 0.0129, -0.0524,  0.0111]],\n",
              " \n",
              "          [[ 0.0519,  0.0084,  0.0402],\n",
              "           [-0.0166, -0.0060, -0.0278],\n",
              "           [-0.0388, -0.0517, -0.0093]]],\n",
              " \n",
              " \n",
              "         [[[-0.0146, -0.0508,  0.0544],\n",
              "           [-0.0138,  0.0132, -0.0003],\n",
              "           [ 0.0209, -0.0194, -0.0385]],\n",
              " \n",
              "          [[ 0.0210,  0.0253, -0.0188],\n",
              "           [ 0.0292, -0.0509,  0.0036],\n",
              "           [-0.0032,  0.0048, -0.0462]],\n",
              " \n",
              "          [[-0.0097,  0.0444,  0.0070],\n",
              "           [ 0.0509,  0.0452, -0.0415],\n",
              "           [ 0.0390,  0.0392,  0.0359]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0497, -0.0084, -0.0432],\n",
              "           [ 0.0013,  0.0160,  0.0580],\n",
              "           [ 0.0144, -0.0356, -0.0565]],\n",
              " \n",
              "          [[ 0.0347,  0.0554,  0.0098],\n",
              "           [ 0.0121,  0.0482,  0.0482],\n",
              "           [ 0.0050, -0.0403,  0.0435]],\n",
              " \n",
              "          [[ 0.0246, -0.0423, -0.0229],\n",
              "           [-0.0080,  0.0118,  0.0115],\n",
              "           [ 0.0190,  0.0428,  0.0509]]],\n",
              " \n",
              " \n",
              "         [[[-0.0074, -0.0029, -0.0292],\n",
              "           [-0.0501,  0.0036, -0.0485],\n",
              "           [-0.0295, -0.0292, -0.0364]],\n",
              " \n",
              "          [[ 0.0364, -0.0575, -0.0512],\n",
              "           [-0.0370, -0.0020,  0.0099],\n",
              "           [ 0.0506, -0.0582,  0.0546]],\n",
              " \n",
              "          [[-0.0535, -0.0037, -0.0264],\n",
              "           [ 0.0105,  0.0275, -0.0271],\n",
              "           [ 0.0093, -0.0238, -0.0057]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0332,  0.0044,  0.0073],\n",
              "           [-0.0573,  0.0564, -0.0482],\n",
              "           [ 0.0009, -0.0049, -0.0027]],\n",
              " \n",
              "          [[-0.0429, -0.0521,  0.0115],\n",
              "           [ 0.0241,  0.0226, -0.0236],\n",
              "           [-0.0315,  0.0319, -0.0526]],\n",
              " \n",
              "          [[-0.0230, -0.0413, -0.0224],\n",
              "           [-0.0283,  0.0230,  0.0549],\n",
              "           [ 0.0543, -0.0426, -0.0090]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0477,  0.0129, -0.0008,  0.0293, -0.0562,  0.0352, -0.0520,  0.0042,\n",
              "         -0.0119, -0.0588, -0.0550,  0.0531,  0.0341, -0.0192, -0.0343,  0.0318,\n",
              "          0.0263,  0.0093, -0.0013,  0.0094, -0.0259,  0.0527, -0.0248, -0.0249,\n",
              "         -0.0333,  0.0580,  0.0299, -0.0046, -0.0160, -0.0289, -0.0161, -0.0506,\n",
              "          0.0311,  0.0195, -0.0096,  0.0550, -0.0543, -0.0520,  0.0406, -0.0021,\n",
              "          0.0416,  0.0283,  0.0249, -0.0073,  0.0276, -0.0249,  0.0297, -0.0009,\n",
              "         -0.0355,  0.0098,  0.0308, -0.0452, -0.0561,  0.0392, -0.0146, -0.0197,\n",
              "          0.0565,  0.0412,  0.0415,  0.0093,  0.0474, -0.0162, -0.0563,  0.0580],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.0213,  0.0292,  0.0073],\n",
              "           [ 0.0207,  0.0179,  0.0273],\n",
              "           [-0.0115, -0.0278,  0.0191]],\n",
              " \n",
              "          [[ 0.0163,  0.0242, -0.0017],\n",
              "           [-0.0113, -0.0198,  0.0372],\n",
              "           [ 0.0203,  0.0407, -0.0080]],\n",
              " \n",
              "          [[-0.0395,  0.0030,  0.0032],\n",
              "           [-0.0326,  0.0120,  0.0342],\n",
              "           [-0.0063,  0.0260, -0.0264]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0182, -0.0100, -0.0248],\n",
              "           [-0.0399, -0.0078, -0.0309],\n",
              "           [ 0.0320, -0.0261, -0.0353]],\n",
              " \n",
              "          [[ 0.0197,  0.0094, -0.0247],\n",
              "           [-0.0282, -0.0254,  0.0097],\n",
              "           [-0.0337,  0.0109,  0.0292]],\n",
              " \n",
              "          [[-0.0178, -0.0223, -0.0288],\n",
              "           [-0.0275,  0.0158,  0.0103],\n",
              "           [-0.0242, -0.0345,  0.0196]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0273,  0.0073, -0.0051],\n",
              "           [-0.0410, -0.0025,  0.0031],\n",
              "           [ 0.0164,  0.0106,  0.0393]],\n",
              " \n",
              "          [[-0.0409, -0.0109,  0.0186],\n",
              "           [ 0.0300,  0.0154, -0.0072],\n",
              "           [ 0.0334, -0.0241, -0.0099]],\n",
              " \n",
              "          [[-0.0351,  0.0408,  0.0146],\n",
              "           [ 0.0022,  0.0262,  0.0102],\n",
              "           [-0.0282,  0.0113, -0.0222]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0066, -0.0137, -0.0064],\n",
              "           [-0.0092, -0.0088, -0.0063],\n",
              "           [ 0.0248, -0.0042, -0.0158]],\n",
              " \n",
              "          [[-0.0298,  0.0318, -0.0383],\n",
              "           [-0.0033, -0.0003,  0.0353],\n",
              "           [-0.0368,  0.0130,  0.0231]],\n",
              " \n",
              "          [[-0.0273, -0.0095,  0.0201],\n",
              "           [ 0.0069, -0.0404,  0.0345],\n",
              "           [ 0.0375, -0.0112, -0.0351]]],\n",
              " \n",
              " \n",
              "         [[[-0.0253,  0.0307, -0.0225],\n",
              "           [-0.0012,  0.0189, -0.0102],\n",
              "           [ 0.0267,  0.0190, -0.0304]],\n",
              " \n",
              "          [[ 0.0350,  0.0092, -0.0198],\n",
              "           [-0.0002, -0.0273,  0.0372],\n",
              "           [ 0.0214, -0.0166, -0.0350]],\n",
              " \n",
              "          [[-0.0306,  0.0297,  0.0289],\n",
              "           [-0.0337, -0.0156,  0.0349],\n",
              "           [-0.0277,  0.0052, -0.0401]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0257, -0.0008, -0.0157],\n",
              "           [ 0.0203,  0.0111,  0.0283],\n",
              "           [-0.0275, -0.0260,  0.0314]],\n",
              " \n",
              "          [[ 0.0109,  0.0383, -0.0365],\n",
              "           [ 0.0103,  0.0321, -0.0015],\n",
              "           [-0.0262, -0.0415,  0.0267]],\n",
              " \n",
              "          [[-0.0032,  0.0385,  0.0010],\n",
              "           [-0.0266, -0.0382, -0.0087],\n",
              "           [-0.0312,  0.0289, -0.0246]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.0092,  0.0246, -0.0356],\n",
              "           [-0.0043, -0.0008, -0.0028],\n",
              "           [ 0.0016,  0.0300,  0.0263]],\n",
              " \n",
              "          [[-0.0272,  0.0291, -0.0408],\n",
              "           [-0.0087, -0.0215, -0.0109],\n",
              "           [-0.0310, -0.0091,  0.0195]],\n",
              " \n",
              "          [[ 0.0191, -0.0202,  0.0296],\n",
              "           [ 0.0100, -0.0236,  0.0124],\n",
              "           [-0.0381,  0.0302, -0.0257]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0338, -0.0085,  0.0262],\n",
              "           [-0.0140,  0.0097,  0.0322],\n",
              "           [-0.0012, -0.0166,  0.0084]],\n",
              " \n",
              "          [[-0.0406, -0.0388, -0.0373],\n",
              "           [-0.0263, -0.0033, -0.0083],\n",
              "           [ 0.0378,  0.0161, -0.0222]],\n",
              " \n",
              "          [[ 0.0215, -0.0202, -0.0320],\n",
              "           [-0.0060,  0.0197,  0.0244],\n",
              "           [ 0.0296, -0.0009,  0.0098]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0197,  0.0394, -0.0332],\n",
              "           [-0.0180,  0.0115, -0.0183],\n",
              "           [-0.0074,  0.0338, -0.0248]],\n",
              " \n",
              "          [[ 0.0405, -0.0151, -0.0282],\n",
              "           [ 0.0141, -0.0260, -0.0416],\n",
              "           [-0.0134, -0.0126,  0.0067]],\n",
              " \n",
              "          [[ 0.0212,  0.0141,  0.0399],\n",
              "           [ 0.0107,  0.0360, -0.0387],\n",
              "           [-0.0014, -0.0067, -0.0196]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0076,  0.0169,  0.0243],\n",
              "           [-0.0189, -0.0056, -0.0233],\n",
              "           [ 0.0203,  0.0099,  0.0396]],\n",
              " \n",
              "          [[-0.0393,  0.0030,  0.0101],\n",
              "           [-0.0106,  0.0355, -0.0193],\n",
              "           [ 0.0387, -0.0203,  0.0403]],\n",
              " \n",
              "          [[-0.0138,  0.0374, -0.0189],\n",
              "           [-0.0280,  0.0087,  0.0222],\n",
              "           [-0.0067, -0.0090,  0.0324]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0005,  0.0062,  0.0245],\n",
              "           [ 0.0068,  0.0368,  0.0049],\n",
              "           [-0.0161,  0.0325, -0.0247]],\n",
              " \n",
              "          [[-0.0180,  0.0034, -0.0218],\n",
              "           [ 0.0107,  0.0037, -0.0110],\n",
              "           [ 0.0108,  0.0023,  0.0288]],\n",
              " \n",
              "          [[ 0.0217,  0.0326,  0.0238],\n",
              "           [-0.0098, -0.0045, -0.0290],\n",
              "           [ 0.0345, -0.0410, -0.0398]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0415,  0.0167,  0.0122],\n",
              "           [ 0.0296,  0.0004, -0.0006],\n",
              "           [ 0.0268, -0.0350,  0.0319]],\n",
              " \n",
              "          [[-0.0306,  0.0014,  0.0023],\n",
              "           [ 0.0252,  0.0294, -0.0399],\n",
              "           [ 0.0390,  0.0217,  0.0265]],\n",
              " \n",
              "          [[-0.0124, -0.0369, -0.0042],\n",
              "           [-0.0003,  0.0081, -0.0191],\n",
              "           [ 0.0382, -0.0229,  0.0276]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0046,  0.0323,  0.0237, -0.0408, -0.0324,  0.0136,  0.0248, -0.0310,\n",
              "          0.0369, -0.0105, -0.0149,  0.0157, -0.0239,  0.0015, -0.0315,  0.0233,\n",
              "          0.0376, -0.0159, -0.0052,  0.0200, -0.0200,  0.0231, -0.0017,  0.0161,\n",
              "          0.0130,  0.0157, -0.0359,  0.0102, -0.0020,  0.0362,  0.0165, -0.0183,\n",
              "         -0.0138, -0.0264,  0.0146, -0.0209,  0.0399,  0.0406, -0.0088, -0.0003,\n",
              "          0.0078, -0.0229, -0.0085,  0.0075,  0.0297, -0.0225,  0.0183, -0.0135,\n",
              "          0.0120,  0.0100,  0.0020, -0.0344, -0.0212,  0.0296, -0.0337, -0.0126,\n",
              "          0.0327,  0.0287, -0.0225,  0.0064,  0.0377, -0.0043,  0.0332,  0.0048,\n",
              "         -0.0308,  0.0164,  0.0274, -0.0243,  0.0092, -0.0308,  0.0221, -0.0408,\n",
              "         -0.0404, -0.0040,  0.0231,  0.0388,  0.0361, -0.0374,  0.0094, -0.0410,\n",
              "          0.0282, -0.0387,  0.0158,  0.0343,  0.0024,  0.0327, -0.0163, -0.0152,\n",
              "          0.0027, -0.0022, -0.0404, -0.0340,  0.0065,  0.0288, -0.0269, -0.0043,\n",
              "          0.0226, -0.0081,  0.0304,  0.0067,  0.0271, -0.0187,  0.0211,  0.0179,\n",
              "         -0.0380, -0.0199, -0.0080,  0.0113, -0.0377,  0.0008, -0.0199,  0.0190,\n",
              "          0.0202,  0.0235,  0.0003,  0.0297, -0.0010, -0.0168, -0.0221,  0.0105,\n",
              "          0.0386,  0.0415, -0.0275, -0.0096,  0.0203, -0.0117,  0.0110, -0.0327],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0313,  0.0412, -0.0553,  ...,  0.0059,  0.0163, -0.0529],\n",
              "         [ 0.0780, -0.0340, -0.0637,  ...,  0.0817,  0.0808,  0.0582],\n",
              "         [-0.0702, -0.0763,  0.0645,  ..., -0.0045,  0.0201, -0.0425],\n",
              "         ...,\n",
              "         [ 0.0720, -0.0647,  0.0213,  ..., -0.0543,  0.0228,  0.0542],\n",
              "         [ 0.0032, -0.0264, -0.0473,  ..., -0.0264, -0.0008, -0.0532],\n",
              "         [ 0.0495, -0.0827, -0.0034,  ...,  0.0830,  0.0428, -0.0476]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0134,  0.0776, -0.0770,  0.0828,  0.0524,  0.0442,  0.0757, -0.0075,\n",
              "         -0.0787, -0.0462,  0.0198, -0.0027, -0.0247, -0.0643, -0.0613, -0.0691,\n",
              "         -0.0829,  0.0238,  0.0698, -0.0646, -0.0613, -0.0160,  0.0693, -0.0730,\n",
              "          0.0597, -0.0596,  0.0770,  0.0623,  0.0647,  0.0182,  0.0843,  0.0455,\n",
              "         -0.0463,  0.0002, -0.0620,  0.0064, -0.0241, -0.0564, -0.0704, -0.0713,\n",
              "         -0.0034, -0.0370,  0.0173,  0.0454,  0.0210,  0.0163, -0.0144,  0.0058,\n",
              "         -0.0101,  0.0607,  0.0761,  0.0177, -0.0615,  0.0269, -0.0346, -0.0608,\n",
              "          0.0311, -0.0515,  0.0249,  0.0155,  0.0738, -0.0696,  0.0008,  0.0412,\n",
              "          0.0496,  0.0256, -0.0420,  0.0601,  0.0333, -0.0636,  0.0291, -0.0597,\n",
              "         -0.0526, -0.0668, -0.0712,  0.0249, -0.0763,  0.0738, -0.0561,  0.0134,\n",
              "          0.0283,  0.0728,  0.0113,  0.0704,  0.0075,  0.0095, -0.0574,  0.0421,\n",
              "          0.0066,  0.0483,  0.0175, -0.0646, -0.0491, -0.0442,  0.0777,  0.0326,\n",
              "         -0.0699,  0.0313,  0.0323,  0.0368, -0.0288, -0.0460,  0.0734, -0.0066,\n",
              "          0.0394,  0.0255,  0.0772, -0.0482, -0.0206, -0.0573,  0.0326, -0.0305,\n",
              "          0.0795, -0.0205,  0.0204, -0.0695,  0.0767,  0.0722,  0.0761,  0.0262,\n",
              "         -0.0759, -0.0790,  0.0813,  0.0343, -0.0567, -0.0646,  0.0628,  0.0879,\n",
              "         -0.0742, -0.0353,  0.0809,  0.0489,  0.0546,  0.0578,  0.0880, -0.0143,\n",
              "          0.0232,  0.0715,  0.0017, -0.0425, -0.0585,  0.0016,  0.0021, -0.0263,\n",
              "          0.0557, -0.0525,  0.0739,  0.0120, -0.0558,  0.0554, -0.0125,  0.0339,\n",
              "         -0.0782,  0.0328,  0.0762, -0.0148, -0.0472, -0.0816, -0.0512,  0.0140,\n",
              "          0.0821, -0.0006, -0.0717,  0.0566, -0.0525,  0.0454,  0.0634, -0.0681,\n",
              "         -0.0489, -0.0489, -0.0863, -0.0076,  0.0133, -0.0531,  0.0843,  0.0058,\n",
              "          0.0250,  0.0136, -0.0670, -0.0252, -0.0832,  0.0638,  0.0328,  0.0530,\n",
              "          0.0326, -0.0566, -0.0759, -0.0556, -0.0640, -0.0202,  0.0809, -0.0694,\n",
              "          0.0126,  0.0415, -0.0552,  0.0167,  0.0707, -0.0843, -0.0097,  0.0303,\n",
              "          0.0604, -0.0719, -0.0398,  0.0262,  0.0770, -0.0564, -0.0760, -0.0843,\n",
              "         -0.0785,  0.0549, -0.0690, -0.0759, -0.0368, -0.0124,  0.0728, -0.0230,\n",
              "         -0.0507,  0.0840,  0.0046,  0.0762, -0.0786,  0.0768, -0.0849,  0.0617,\n",
              "         -0.0131,  0.0521,  0.0364, -0.0668, -0.0254,  0.0820, -0.0458,  0.0603,\n",
              "         -0.0863, -0.0825, -0.0411,  0.0659,  0.0513, -0.0350, -0.0051,  0.0259,\n",
              "          0.0213, -0.0744,  0.0765,  0.0087,  0.0587, -0.0162, -0.0883, -0.0839,\n",
              "         -0.0335,  0.0568, -0.0445, -0.0082,  0.0031,  0.0793,  0.0826, -0.0627,\n",
              "         -0.0699, -0.0296,  0.0390, -0.0404, -0.0300,  0.0672, -0.0550,  0.0862,\n",
              "          0.0685,  0.0783, -0.0376, -0.0426, -0.0567, -0.0701, -0.0632,  0.0485,\n",
              "          0.0196,  0.0587, -0.0668, -0.0467,  0.0252, -0.0121,  0.0055, -0.0273,\n",
              "         -0.0484,  0.0324, -0.0849,  0.0164,  0.0690,  0.0160, -0.0356, -0.0115,\n",
              "          0.0457, -0.0148, -0.0408, -0.0523, -0.0117,  0.0020,  0.0311,  0.0247,\n",
              "         -0.0111,  0.0479,  0.0525, -0.0714, -0.0587,  0.0873, -0.0378,  0.0115,\n",
              "         -0.0231, -0.0749,  0.0403, -0.0465, -0.0235, -0.0631, -0.0161, -0.0671,\n",
              "          0.0655, -0.0668, -0.0632,  0.0694, -0.0204,  0.0667,  0.0499, -0.0416,\n",
              "         -0.0156, -0.0861,  0.0675,  0.0375, -0.0069, -0.0849,  0.0582,  0.0523,\n",
              "          0.0730, -0.0392, -0.0640,  0.0353,  0.0717,  0.0203,  0.0375, -0.0398,\n",
              "          0.0720, -0.0334,  0.0297,  0.0164,  0.0193,  0.0533, -0.0815,  0.0755,\n",
              "          0.0246, -0.0191,  0.0760, -0.0340,  0.0517,  0.0256, -0.0542,  0.0457,\n",
              "          0.0590, -0.0478,  0.0181, -0.0053, -0.0828, -0.0287,  0.0106, -0.0693,\n",
              "         -0.0038, -0.0608, -0.0762, -0.0439, -0.0778,  0.0580, -0.0745,  0.0746,\n",
              "         -0.0360, -0.0068,  0.0250,  0.0431,  0.0027, -0.0192,  0.0558, -0.0673,\n",
              "         -0.0608, -0.0073,  0.0783, -0.0629, -0.0146,  0.0477,  0.0294, -0.0047,\n",
              "         -0.0413,  0.0615, -0.0812,  0.0031, -0.0290, -0.0004,  0.0677,  0.0808,\n",
              "          0.0670,  0.0423, -0.0734,  0.0404,  0.0727, -0.0603,  0.0691, -0.0108,\n",
              "          0.0691,  0.0744,  0.0744, -0.0154,  0.0874, -0.0268,  0.0005,  0.0227,\n",
              "          0.0522, -0.0136, -0.0540,  0.0784, -0.0266, -0.0470,  0.0189, -0.0070,\n",
              "          0.0559, -0.0410,  0.0857,  0.0120, -0.0501, -0.0317,  0.0457,  0.0224,\n",
              "         -0.0434,  0.0344,  0.0668, -0.0230, -0.0099, -0.0030, -0.0788, -0.0655,\n",
              "         -0.0477, -0.0333, -0.0628, -0.0649, -0.0335,  0.0398,  0.0541, -0.0446,\n",
              "          0.0159,  0.0614, -0.0193, -0.0201, -0.0871,  0.0332,  0.0436,  0.0629,\n",
              "         -0.0066,  0.0426, -0.0454, -0.0051,  0.0583,  0.0404,  0.0119, -0.0634,\n",
              "          0.0828, -0.0204,  0.0572, -0.0303,  0.0133, -0.0182, -0.0246,  0.0190,\n",
              "         -0.0520,  0.0120, -0.0535,  0.0574, -0.0721,  0.0087, -0.0693, -0.0486,\n",
              "         -0.0849, -0.0397,  0.0711, -0.0382,  0.0753, -0.0091,  0.0702,  0.0574,\n",
              "         -0.0499, -0.0751, -0.0473,  0.0576,  0.0669, -0.0366,  0.0073,  0.0288,\n",
              "         -0.0753,  0.0130, -0.0178,  0.0484,  0.0244, -0.0586, -0.0345, -0.0639,\n",
              "         -0.0598,  0.0848, -0.0620, -0.0280, -0.0083, -0.0293,  0.0179,  0.0786,\n",
              "          0.0474,  0.0830,  0.0267, -0.0471, -0.0694, -0.0284,  0.0383,  0.0563],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0297,  0.0440,  0.0195,  ...,  0.0213, -0.0166,  0.0336],\n",
              "         [ 0.0351, -0.0056,  0.0202,  ..., -0.0152, -0.0419,  0.0146],\n",
              "         [ 0.0154, -0.0071, -0.0288,  ...,  0.0352, -0.0038,  0.0261],\n",
              "         ...,\n",
              "         [ 0.0310, -0.0326, -0.0414,  ..., -0.0412, -0.0226, -0.0199],\n",
              "         [-0.0092, -0.0032,  0.0389,  ...,  0.0043,  0.0336, -0.0323],\n",
              "         [-0.0015,  0.0188,  0.0417,  ..., -0.0024, -0.0237,  0.0139]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-1.1220e-02, -6.3605e-03,  1.6697e-02, -2.6421e-02, -2.1095e-02,\n",
              "         -1.7157e-02,  7.6636e-04,  1.5952e-02, -1.0546e-02, -5.9734e-03,\n",
              "          3.9221e-02, -2.2182e-02, -1.1761e-02, -4.9406e-03, -3.4599e-02,\n",
              "         -2.1961e-02,  3.7131e-02, -1.4514e-02,  1.5260e-02, -3.0948e-02,\n",
              "         -1.7663e-04,  3.0407e-02,  1.1475e-02,  1.6197e-02,  2.6298e-02,\n",
              "          1.8721e-02, -1.0593e-02, -4.3212e-02,  2.6105e-02, -3.7599e-03,\n",
              "         -2.7239e-02,  1.8762e-02, -2.1856e-03, -6.9192e-03, -3.1217e-02,\n",
              "          1.4775e-03, -4.8057e-03, -2.8908e-02,  5.8323e-03,  3.0287e-02,\n",
              "          2.8263e-02,  1.9011e-02, -2.6786e-03, -1.3738e-02, -1.9022e-02,\n",
              "         -2.6509e-02,  3.0579e-02, -3.5349e-02, -4.4710e-03, -4.2167e-02,\n",
              "          5.8045e-03, -1.3995e-02,  1.6472e-02,  1.9604e-02, -1.7323e-02,\n",
              "         -2.4624e-02,  3.1349e-02,  2.1794e-02, -1.4991e-02,  2.8581e-03,\n",
              "         -1.4359e-02, -2.9674e-02, -5.3666e-03,  1.1138e-02, -2.1670e-02,\n",
              "         -3.3159e-02, -2.6304e-02, -2.0589e-02,  1.0838e-02, -4.0431e-02,\n",
              "         -2.6303e-02,  1.0569e-03, -2.8525e-02,  4.4573e-03, -3.2069e-02,\n",
              "         -1.5925e-03, -1.2157e-03, -1.7135e-03, -1.8969e-02, -2.8041e-03,\n",
              "         -2.9492e-02, -2.1127e-02,  3.2611e-02,  3.9785e-02, -2.4900e-02,\n",
              "          2.9915e-03,  4.0419e-02,  2.4085e-02,  3.9734e-02, -1.5144e-02,\n",
              "          3.9377e-02, -3.0173e-02, -3.3101e-02,  2.1355e-02, -1.6179e-02,\n",
              "          2.3342e-02,  7.3865e-03, -4.0865e-03,  1.2413e-02, -3.4581e-02,\n",
              "         -4.0046e-02,  2.2267e-02, -3.1161e-02,  1.6807e-02,  2.2017e-02,\n",
              "         -2.6514e-02,  1.7707e-02,  2.7551e-02, -1.5220e-02, -4.9771e-03,\n",
              "         -3.6561e-03, -3.4823e-02,  4.3966e-02,  1.9382e-02, -2.8836e-02,\n",
              "         -2.0859e-02, -3.1146e-02,  6.3191e-03, -3.5709e-02, -2.2865e-02,\n",
              "         -4.0776e-03,  4.4055e-02,  3.3912e-02, -1.8999e-02,  1.6787e-03,\n",
              "          3.2966e-02, -2.3311e-02,  1.1764e-03,  3.8852e-02,  1.2107e-02,\n",
              "         -2.9157e-02, -1.2683e-02,  2.4590e-02, -2.7719e-03, -4.0168e-03,\n",
              "         -3.5462e-02, -4.3598e-02,  2.5512e-02, -7.7307e-03, -1.6021e-02,\n",
              "          2.0483e-02,  9.0393e-03,  3.2768e-02, -1.9591e-02, -3.8190e-02,\n",
              "         -6.9716e-03, -2.1187e-02,  3.5759e-02, -1.5696e-02,  6.2084e-03,\n",
              "         -4.2914e-02, -1.0151e-03,  4.3238e-02, -1.3774e-02,  1.7887e-02,\n",
              "         -2.1329e-03,  3.4861e-02, -2.0738e-02,  2.5049e-02,  4.0955e-02,\n",
              "          2.6313e-02, -4.7604e-03,  2.0798e-02, -1.7805e-03,  4.3083e-02,\n",
              "          1.9670e-02, -3.4104e-02, -3.1166e-02,  1.6016e-02,  1.4729e-02,\n",
              "          1.1840e-02, -6.0416e-03, -2.8343e-02, -4.0133e-02,  3.3583e-04,\n",
              "          2.2979e-02, -4.0856e-02,  3.9855e-02,  3.8429e-02, -1.4790e-02,\n",
              "          7.4486e-03,  6.3373e-03, -2.2596e-02, -4.8844e-03,  9.4014e-03,\n",
              "         -2.1999e-02, -2.1325e-02,  2.3284e-02, -3.9527e-02,  2.6939e-02,\n",
              "          1.3524e-02, -2.7217e-02,  1.0447e-02,  1.3848e-02, -2.3475e-02,\n",
              "          2.2525e-02, -4.2680e-02,  2.1208e-02,  1.8123e-02, -1.6778e-02,\n",
              "          1.5789e-02, -2.9644e-02,  1.2923e-02,  3.5437e-02, -3.7577e-02,\n",
              "          1.3409e-03,  1.0512e-02, -8.8851e-03,  1.4600e-03, -3.3069e-02,\n",
              "         -2.4204e-02, -2.9844e-03,  2.8721e-02, -2.9081e-02,  6.8193e-03,\n",
              "          7.4853e-05, -5.1742e-03, -5.0119e-03, -1.6066e-03,  4.6833e-04,\n",
              "         -9.3520e-03,  3.0755e-02, -2.7904e-02,  1.6991e-02,  2.8316e-02,\n",
              "         -2.9595e-02, -3.0501e-02, -3.2013e-03, -2.9033e-03, -1.5344e-02,\n",
              "         -4.0632e-02, -3.8479e-02,  3.2977e-02, -2.9333e-02,  1.6522e-02,\n",
              "         -1.2025e-02,  7.9962e-03, -1.7313e-02,  2.0844e-03, -1.1150e-02,\n",
              "         -3.3140e-02,  1.3040e-02, -3.2812e-02,  3.1316e-02,  2.8180e-02,\n",
              "          1.9134e-02,  4.3375e-02,  3.0164e-02, -3.7547e-02,  4.9137e-04,\n",
              "          3.2341e-03, -2.5911e-02,  4.1002e-03,  2.0398e-02, -2.7819e-02,\n",
              "          3.6777e-02], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0171, -0.0406,  0.0082,  ...,  0.0441, -0.0236,  0.0003],\n",
              "         [-0.0345, -0.0171, -0.0042,  ..., -0.0119,  0.0613,  0.0345],\n",
              "         [-0.0152, -0.0475,  0.0176,  ..., -0.0477, -0.0043, -0.0554],\n",
              "         ...,\n",
              "         [ 0.0004, -0.0015, -0.0169,  ...,  0.0467,  0.0097, -0.0507],\n",
              "         [-0.0373,  0.0213,  0.0311,  ...,  0.0546,  0.0427,  0.0425],\n",
              "         [ 0.0154,  0.0229,  0.0227,  ..., -0.0058,  0.0301, -0.0612]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0592,  0.0341,  0.0113,  0.0568, -0.0017, -0.0386, -0.0230, -0.0073,\n",
              "         -0.0080,  0.0412,  0.0056,  0.0273,  0.0334, -0.0398, -0.0280, -0.0055,\n",
              "         -0.0443, -0.0091, -0.0265,  0.0061,  0.0616,  0.0322,  0.0060, -0.0079,\n",
              "          0.0444,  0.0497, -0.0051,  0.0252,  0.0221, -0.0125, -0.0304,  0.0232],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.1154,  0.0857,  0.1465, -0.1735, -0.0374,  0.0237, -0.0690,  0.1708,\n",
              "          -0.1545, -0.1424, -0.1036, -0.0350,  0.0468,  0.0246, -0.1709,  0.0746,\n",
              "           0.0465, -0.1709,  0.1350,  0.0482,  0.1626,  0.0773,  0.0757, -0.0350,\n",
              "           0.0065,  0.1310, -0.0060, -0.1688,  0.0313,  0.1182,  0.0811, -0.1675],\n",
              "         [ 0.0977,  0.0734, -0.0721,  0.1303,  0.0966, -0.1449, -0.0475, -0.1697,\n",
              "          -0.1376, -0.0114,  0.0169, -0.1177,  0.0157,  0.1015,  0.1604,  0.1583,\n",
              "          -0.1372,  0.0182,  0.0955, -0.0979, -0.0855, -0.0137,  0.1239,  0.0528,\n",
              "          -0.1745, -0.0739,  0.0013,  0.1437, -0.0787, -0.0298, -0.0393,  0.1354],\n",
              "         [ 0.0764, -0.0879, -0.0512, -0.0369,  0.0801,  0.1682, -0.0716,  0.0542,\n",
              "          -0.0254,  0.0327, -0.1319, -0.1199,  0.0789,  0.1106,  0.1736, -0.0494,\n",
              "           0.0882, -0.0643,  0.1651,  0.0700,  0.0042,  0.0334, -0.0456,  0.1699,\n",
              "          -0.1345,  0.0047,  0.0409, -0.0632,  0.1430,  0.0558, -0.0270, -0.0180],\n",
              "         [ 0.1665,  0.1044, -0.0226, -0.1345,  0.1543,  0.1582, -0.1697,  0.0720,\n",
              "          -0.1444, -0.1059, -0.0729,  0.0926, -0.0075, -0.1016,  0.1220,  0.0029,\n",
              "          -0.0389,  0.1054,  0.0679,  0.1368, -0.1625, -0.0257, -0.1625,  0.0682,\n",
              "           0.0380, -0.0483,  0.1260, -0.0421,  0.0724, -0.1266, -0.0949, -0.0576],\n",
              "         [ 0.0352, -0.1453, -0.1630,  0.1602, -0.0994, -0.0449, -0.1001,  0.0582,\n",
              "          -0.0990,  0.1643, -0.0366,  0.1161,  0.1599,  0.1556, -0.1645, -0.0915,\n",
              "          -0.1283,  0.0166, -0.0183, -0.1147, -0.1647, -0.0816, -0.0823,  0.0071,\n",
              "           0.1069, -0.0041,  0.0662, -0.1181, -0.1748,  0.0685,  0.1313,  0.0577],\n",
              "         [ 0.0310,  0.0429, -0.0813,  0.0109,  0.1097, -0.0544, -0.1493,  0.1488,\n",
              "           0.0859, -0.1284, -0.1264, -0.0602,  0.0634,  0.1163, -0.0244, -0.0922,\n",
              "           0.0164, -0.0137,  0.1091, -0.0593,  0.0419,  0.0852,  0.0074,  0.1106,\n",
              "          -0.1753,  0.1433, -0.0373, -0.1317,  0.0586,  0.0190,  0.0898, -0.0305],\n",
              "         [-0.0652,  0.0966,  0.0891, -0.1284,  0.0636, -0.0788,  0.0657,  0.0180,\n",
              "           0.1143,  0.0276,  0.1581, -0.1534,  0.1732,  0.1502, -0.0650, -0.0019,\n",
              "          -0.0325,  0.0075, -0.0416,  0.0459,  0.0545, -0.1295, -0.0240,  0.0313,\n",
              "           0.0546, -0.1273, -0.0818, -0.1533,  0.0015,  0.0505, -0.0630,  0.1671],\n",
              "         [-0.1417,  0.0326,  0.1621, -0.1277, -0.0721,  0.1616,  0.1273, -0.0600,\n",
              "           0.1527, -0.1290,  0.0141, -0.0933, -0.1690,  0.0417,  0.0513, -0.1357,\n",
              "          -0.1544,  0.1732, -0.0647, -0.0672,  0.0569,  0.1283,  0.0596, -0.0132,\n",
              "          -0.0550,  0.1422,  0.0790, -0.1242,  0.1570,  0.0400,  0.1112, -0.1401],\n",
              "         [ 0.0374, -0.1058, -0.0475,  0.1630,  0.1567,  0.0099,  0.1120,  0.0576,\n",
              "          -0.0435,  0.1331,  0.0424, -0.0141,  0.0809,  0.1710, -0.0736,  0.0888,\n",
              "          -0.1467,  0.0807, -0.1251, -0.0943, -0.0661, -0.0413,  0.0686,  0.0709,\n",
              "          -0.1113,  0.1156, -0.0103, -0.1172,  0.0890, -0.0777,  0.1463, -0.0081],\n",
              "         [-0.1319,  0.1250, -0.0745,  0.1454,  0.1627,  0.1724, -0.0298, -0.1229,\n",
              "          -0.1549, -0.1307, -0.1601, -0.1706,  0.0159,  0.1759,  0.0376, -0.0011,\n",
              "          -0.1203,  0.1614, -0.0595,  0.1383,  0.1753, -0.0367,  0.0190,  0.1384,\n",
              "          -0.0519, -0.0637,  0.1434,  0.0655, -0.0270,  0.0990,  0.0611,  0.0776]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0417, -0.1093, -0.0348, -0.0110, -0.1623, -0.0189, -0.0738,  0.0426,\n",
              "         -0.1705,  0.1345], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(cnn_model,input_size=(1,28,28),device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewll-zW6qs22",
        "outputId": "2cb3aaa5-d9f9-4839-806c-2cd9112d6e30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             160\n",
            "         MaxPool2d-2           [-1, 16, 14, 14]               0\n",
            "       BatchNorm2d-3           [-1, 16, 14, 14]              32\n",
            "            Conv2d-4           [-1, 32, 14, 14]           4,640\n",
            "         MaxPool2d-5             [-1, 32, 7, 7]               0\n",
            "       BatchNorm2d-6             [-1, 32, 7, 7]              64\n",
            "            Conv2d-7             [-1, 64, 7, 7]          18,496\n",
            "         MaxPool2d-8             [-1, 64, 3, 3]               0\n",
            "       BatchNorm2d-9             [-1, 64, 3, 3]             128\n",
            "           Conv2d-10            [-1, 128, 3, 3]          73,856\n",
            "        MaxPool2d-11            [-1, 128, 1, 1]               0\n",
            "           Linear-12                  [-1, 512]          66,048\n",
            "           Linear-13                  [-1, 256]         131,328\n",
            "           Linear-14                   [-1, 32]           8,224\n",
            "           Linear-15                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 303,306\n",
            "Trainable params: 303,306\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.26\n",
            "Params size (MB): 1.16\n",
            "Estimated Total Size (MB): 1.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(params=cnn_model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "B9b2rxKTrU0O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "4P8X6BjJsPpk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(TensorDataset(x_train.float(),y_train),\n",
        "                          batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "CKdLFm1-r64L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "cnn_model=cnn_model.to(\"cuda\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  training_loss=0.0\n",
        "  for batch,target in train_loader:\n",
        "    batch = batch.to(\"cuda\")\n",
        "    target = target.to(\"cuda\")\n",
        "\n",
        "    opt.zero_grad()\n",
        "    output = cnn_model(batch)\n",
        "    loss = F.cross_entropy(output,target)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    training_loss += loss.item()\n",
        "\n",
        "if (epoch+1)%5 ==0:\n",
        "  print(f\"Training loss: {training_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SrQEonMtPPm",
        "outputId": "3f63b23c-08e7-42ca-d0b2-847f946bc046"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.930609177180515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_test = cnn_model(x_test.float().to(\"cuda\")).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "_a6vEvu_unCR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(preds_test,axis = 1)"
      ],
      "metadata": {
        "id": "3jAuCZOu2KZA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "97R_MrQ42hGu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(pred,y_test.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "dFdc5K3O2jT7",
        "outputId": "51335944-0e43-419a-c8df-3536b6aec485"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0    0     1     2     3    4    5    6     7    8    9\n",
              "row_0                                                      \n",
              "0      975     0     0     0    0    1    2     0    1    0\n",
              "1        0  1134     0     0    7    0    1    11    0    3\n",
              "2        2     0  1028     2    2    0    0     4    1    0\n",
              "3        0     0     0  1007    0    8    0     1    1    0\n",
              "4        0     0     1     0  963    0    0     0    0    3\n",
              "5        0     0     0     1    0  881    2     0    0    4\n",
              "6        1     0     0     0    1    1  953     0    0    1\n",
              "7        1     1     3     0    0    0    0  1009    0    1\n",
              "8        0     0     0     0    0    1    0     0  969    3\n",
              "9        1     0     0     0    9    0    0     3    2  994"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4798c011-24f3-4620-b39a-8948d97123ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1028</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>963</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>881</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>953</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1009</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>969</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4798c011-24f3-4620-b39a-8948d97123ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4798c011-24f3-4620-b39a-8948d97123ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4798c011-24f3-4620-b39a-8948d97123ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1BYUgQe2p-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}